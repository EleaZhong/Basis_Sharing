{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1464ca23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bbml.foundations.gpt2 import GPT2Foundation, GPTConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db01f988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights from pretrained gpt: gpt2\n",
      "forcing vocab_size=50257, block_size=1024, bias=True\n",
      "number of parameters: 123.65M\n"
     ]
    }
   ],
   "source": [
    "foundation = GPT2Foundation(\n",
    "    GPTConfig(),\n",
    "    None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dc1b09a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': GPT2Foundation(\n",
       "   (model): GPT(\n",
       "     (transformer): ModuleDict(\n",
       "       (wte): Embedding(50257, 768)\n",
       "       (wpe): Embedding(1024, 768)\n",
       "       (drop): Dropout(p=0.0, inplace=False)\n",
       "       (h): ModuleList(\n",
       "         (0-11): 12 x Block(\n",
       "           (ln_1): LayerNorm()\n",
       "           (attn): CausalSelfAttention(\n",
       "             (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
       "             (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "             (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (ln_2): LayerNorm()\n",
       "           (mlp): MLP(\n",
       "             (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (gelu): GELU(approximate='none')\n",
       "             (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (dropout): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (ln_f): LayerNorm()\n",
       "     )\n",
       "     (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       "   )\n",
       " ),\n",
       " 'model': GPT(\n",
       "   (transformer): ModuleDict(\n",
       "     (wte): Embedding(50257, 768)\n",
       "     (wpe): Embedding(1024, 768)\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "     (h): ModuleList(\n",
       "       (0-11): 12 x Block(\n",
       "         (ln_1): LayerNorm()\n",
       "         (attn): CausalSelfAttention(\n",
       "           (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
       "           (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "           (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "         (ln_2): LayerNorm()\n",
       "         (mlp): MLP(\n",
       "           (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "           (gelu): GELU(approximate='none')\n",
       "           (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           (dropout): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (ln_f): LayerNorm()\n",
       "   )\n",
       "   (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       " ),\n",
       " 'model.transformer': ModuleDict(\n",
       "   (wte): Embedding(50257, 768)\n",
       "   (wpe): Embedding(1024, 768)\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       "   (h): ModuleList(\n",
       "     (0-11): 12 x Block(\n",
       "       (ln_1): LayerNorm()\n",
       "       (attn): CausalSelfAttention(\n",
       "         (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
       "         (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "         (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "       (ln_2): LayerNorm()\n",
       "       (mlp): MLP(\n",
       "         (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "         (gelu): GELU(approximate='none')\n",
       "         (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "         (dropout): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (ln_f): LayerNorm()\n",
       " ),\n",
       " 'model.transformer.wte': Embedding(50257, 768),\n",
       " 'model.transformer.wpe': Embedding(1024, 768),\n",
       " 'model.transformer.drop': Dropout(p=0.0, inplace=False),\n",
       " 'model.transformer.h': ModuleList(\n",
       "   (0-11): 12 x Block(\n",
       "     (ln_1): LayerNorm()\n",
       "     (attn): CausalSelfAttention(\n",
       "       (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
       "       (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "       (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "     (ln_2): LayerNorm()\n",
       "     (mlp): MLP(\n",
       "       (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "       (gelu): GELU(approximate='none')\n",
       "       (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "       (dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'model.transformer.h.0': Block(\n",
       "   (ln_1): LayerNorm()\n",
       "   (attn): CausalSelfAttention(\n",
       "     (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
       "     (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "     (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (ln_2): LayerNorm()\n",
       "   (mlp): MLP(\n",
       "     (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "     (gelu): GELU(approximate='none')\n",
       "     (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "     (dropout): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'model.transformer.h.0.ln_1': LayerNorm(),\n",
       " 'model.transformer.h.0.attn': CausalSelfAttention(\n",
       "   (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
       "   (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "   (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'model.transformer.h.0.attn.c_attn': Linear(in_features=768, out_features=2304, bias=True),\n",
       " 'model.transformer.h.0.attn.c_proj': Linear(in_features=768, out_features=768, bias=True),\n",
       " 'model.transformer.h.0.attn.attn_dropout': Dropout(p=0.0, inplace=False),\n",
       " 'model.transformer.h.0.attn.resid_dropout': Dropout(p=0.0, inplace=False),\n",
       " 'model.transformer.h.0.ln_2': LayerNorm(),\n",
       " 'model.transformer.h.0.mlp': MLP(\n",
       "   (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "   (gelu): GELU(approximate='none')\n",
       "   (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "   (dropout): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'model.transformer.h.0.mlp.c_fc': Linear(in_features=768, out_features=3072, bias=True),\n",
       " 'model.transformer.h.0.mlp.gelu': GELU(approximate='none'),\n",
       " 'model.transformer.h.0.mlp.c_proj': Linear(in_features=3072, out_features=768, bias=True),\n",
       " 'model.transformer.h.0.mlp.dropout': Dropout(p=0.0, inplace=False),\n",
       " 'model.transformer.h.1': Block(\n",
       "   (ln_1): LayerNorm()\n",
       "   (attn): CausalSelfAttention(\n",
       "     (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
       "     (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "     (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (ln_2): LayerNorm()\n",
       "   (mlp): MLP(\n",
       "     (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "     (gelu): GELU(approximate='none')\n",
       "     (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "     (dropout): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'model.transformer.h.1.ln_1': LayerNorm(),\n",
       " 'model.transformer.h.1.attn': CausalSelfAttention(\n",
       "   (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
       "   (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "   (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'model.transformer.h.1.attn.c_attn': Linear(in_features=768, out_features=2304, bias=True),\n",
       " 'model.transformer.h.1.attn.c_proj': Linear(in_features=768, out_features=768, bias=True),\n",
       " 'model.transformer.h.1.attn.attn_dropout': Dropout(p=0.0, inplace=False),\n",
       " 'model.transformer.h.1.attn.resid_dropout': Dropout(p=0.0, inplace=False),\n",
       " 'model.transformer.h.1.ln_2': LayerNorm(),\n",
       " 'model.transformer.h.1.mlp': MLP(\n",
       "   (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "   (gelu): GELU(approximate='none')\n",
       "   (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "   (dropout): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'model.transformer.h.1.mlp.c_fc': Linear(in_features=768, out_features=3072, bias=True),\n",
       " 'model.transformer.h.1.mlp.gelu': GELU(approximate='none'),\n",
       " 'model.transformer.h.1.mlp.c_proj': Linear(in_features=3072, out_features=768, bias=True),\n",
       " 'model.transformer.h.1.mlp.dropout': Dropout(p=0.0, inplace=False),\n",
       " 'model.transformer.h.2': Block(\n",
       "   (ln_1): LayerNorm()\n",
       "   (attn): CausalSelfAttention(\n",
       "     (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
       "     (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "     (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (ln_2): LayerNorm()\n",
       "   (mlp): MLP(\n",
       "     (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "     (gelu): GELU(approximate='none')\n",
       "     (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "     (dropout): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'model.transformer.h.2.ln_1': LayerNorm(),\n",
       " 'model.transformer.h.2.attn': CausalSelfAttention(\n",
       "   (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
       "   (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "   (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'model.transformer.h.2.attn.c_attn': Linear(in_features=768, out_features=2304, bias=True),\n",
       " 'model.transformer.h.2.attn.c_proj': Linear(in_features=768, out_features=768, bias=True),\n",
       " 'model.transformer.h.2.attn.attn_dropout': Dropout(p=0.0, inplace=False),\n",
       " 'model.transformer.h.2.attn.resid_dropout': Dropout(p=0.0, inplace=False),\n",
       " 'model.transformer.h.2.ln_2': LayerNorm(),\n",
       " 'model.transformer.h.2.mlp': MLP(\n",
       "   (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "   (gelu): GELU(approximate='none')\n",
       "   (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "   (dropout): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'model.transformer.h.2.mlp.c_fc': Linear(in_features=768, out_features=3072, bias=True),\n",
       " 'model.transformer.h.2.mlp.gelu': GELU(approximate='none'),\n",
       " 'model.transformer.h.2.mlp.c_proj': Linear(in_features=3072, out_features=768, bias=True),\n",
       " 'model.transformer.h.2.mlp.dropout': Dropout(p=0.0, inplace=False),\n",
       " 'model.transformer.h.3': Block(\n",
       "   (ln_1): LayerNorm()\n",
       "   (attn): CausalSelfAttention(\n",
       "     (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
       "     (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "     (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (ln_2): LayerNorm()\n",
       "   (mlp): MLP(\n",
       "     (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "     (gelu): GELU(approximate='none')\n",
       "     (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "     (dropout): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'model.transformer.h.3.ln_1': LayerNorm(),\n",
       " 'model.transformer.h.3.attn': CausalSelfAttention(\n",
       "   (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
       "   (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "   (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'model.transformer.h.3.attn.c_attn': Linear(in_features=768, out_features=2304, bias=True),\n",
       " 'model.transformer.h.3.attn.c_proj': Linear(in_features=768, out_features=768, bias=True),\n",
       " 'model.transformer.h.3.attn.attn_dropout': Dropout(p=0.0, inplace=False),\n",
       " 'model.transformer.h.3.attn.resid_dropout': Dropout(p=0.0, inplace=False),\n",
       " 'model.transformer.h.3.ln_2': LayerNorm(),\n",
       " 'model.transformer.h.3.mlp': MLP(\n",
       "   (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "   (gelu): GELU(approximate='none')\n",
       "   (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "   (dropout): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'model.transformer.h.3.mlp.c_fc': Linear(in_features=768, out_features=3072, bias=True),\n",
       " 'model.transformer.h.3.mlp.gelu': GELU(approximate='none'),\n",
       " 'model.transformer.h.3.mlp.c_proj': Linear(in_features=3072, out_features=768, bias=True),\n",
       " 'model.transformer.h.3.mlp.dropout': Dropout(p=0.0, inplace=False),\n",
       " 'model.transformer.h.4': Block(\n",
       "   (ln_1): LayerNorm()\n",
       "   (attn): CausalSelfAttention(\n",
       "     (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
       "     (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "     (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (ln_2): LayerNorm()\n",
       "   (mlp): MLP(\n",
       "     (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "     (gelu): GELU(approximate='none')\n",
       "     (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "     (dropout): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'model.transformer.h.4.ln_1': LayerNorm(),\n",
       " 'model.transformer.h.4.attn': CausalSelfAttention(\n",
       "   (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
       "   (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "   (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'model.transformer.h.4.attn.c_attn': Linear(in_features=768, out_features=2304, bias=True),\n",
       " 'model.transformer.h.4.attn.c_proj': Linear(in_features=768, out_features=768, bias=True),\n",
       " 'model.transformer.h.4.attn.attn_dropout': Dropout(p=0.0, inplace=False),\n",
       " 'model.transformer.h.4.attn.resid_dropout': Dropout(p=0.0, inplace=False),\n",
       " 'model.transformer.h.4.ln_2': LayerNorm(),\n",
       " 'model.transformer.h.4.mlp': MLP(\n",
       "   (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "   (gelu): GELU(approximate='none')\n",
       "   (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "   (dropout): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'model.transformer.h.4.mlp.c_fc': Linear(in_features=768, out_features=3072, bias=True),\n",
       " 'model.transformer.h.4.mlp.gelu': GELU(approximate='none'),\n",
       " 'model.transformer.h.4.mlp.c_proj': Linear(in_features=3072, out_features=768, bias=True),\n",
       " 'model.transformer.h.4.mlp.dropout': Dropout(p=0.0, inplace=False),\n",
       " 'model.transformer.h.5': Block(\n",
       "   (ln_1): LayerNorm()\n",
       "   (attn): CausalSelfAttention(\n",
       "     (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
       "     (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "     (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (ln_2): LayerNorm()\n",
       "   (mlp): MLP(\n",
       "     (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "     (gelu): GELU(approximate='none')\n",
       "     (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "     (dropout): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'model.transformer.h.5.ln_1': LayerNorm(),\n",
       " 'model.transformer.h.5.attn': CausalSelfAttention(\n",
       "   (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
       "   (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "   (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'model.transformer.h.5.attn.c_attn': Linear(in_features=768, out_features=2304, bias=True),\n",
       " 'model.transformer.h.5.attn.c_proj': Linear(in_features=768, out_features=768, bias=True),\n",
       " 'model.transformer.h.5.attn.attn_dropout': Dropout(p=0.0, inplace=False),\n",
       " 'model.transformer.h.5.attn.resid_dropout': Dropout(p=0.0, inplace=False),\n",
       " 'model.transformer.h.5.ln_2': LayerNorm(),\n",
       " 'model.transformer.h.5.mlp': MLP(\n",
       "   (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "   (gelu): GELU(approximate='none')\n",
       "   (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "   (dropout): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'model.transformer.h.5.mlp.c_fc': Linear(in_features=768, out_features=3072, bias=True),\n",
       " 'model.transformer.h.5.mlp.gelu': GELU(approximate='none'),\n",
       " 'model.transformer.h.5.mlp.c_proj': Linear(in_features=3072, out_features=768, bias=True),\n",
       " 'model.transformer.h.5.mlp.dropout': Dropout(p=0.0, inplace=False),\n",
       " 'model.transformer.h.6': Block(\n",
       "   (ln_1): LayerNorm()\n",
       "   (attn): CausalSelfAttention(\n",
       "     (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
       "     (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "     (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (ln_2): LayerNorm()\n",
       "   (mlp): MLP(\n",
       "     (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "     (gelu): GELU(approximate='none')\n",
       "     (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "     (dropout): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'model.transformer.h.6.ln_1': LayerNorm(),\n",
       " 'model.transformer.h.6.attn': CausalSelfAttention(\n",
       "   (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
       "   (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "   (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'model.transformer.h.6.attn.c_attn': Linear(in_features=768, out_features=2304, bias=True),\n",
       " 'model.transformer.h.6.attn.c_proj': Linear(in_features=768, out_features=768, bias=True),\n",
       " 'model.transformer.h.6.attn.attn_dropout': Dropout(p=0.0, inplace=False),\n",
       " 'model.transformer.h.6.attn.resid_dropout': Dropout(p=0.0, inplace=False),\n",
       " 'model.transformer.h.6.ln_2': LayerNorm(),\n",
       " 'model.transformer.h.6.mlp': MLP(\n",
       "   (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "   (gelu): GELU(approximate='none')\n",
       "   (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "   (dropout): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'model.transformer.h.6.mlp.c_fc': Linear(in_features=768, out_features=3072, bias=True),\n",
       " 'model.transformer.h.6.mlp.gelu': GELU(approximate='none'),\n",
       " 'model.transformer.h.6.mlp.c_proj': Linear(in_features=3072, out_features=768, bias=True),\n",
       " 'model.transformer.h.6.mlp.dropout': Dropout(p=0.0, inplace=False),\n",
       " 'model.transformer.h.7': Block(\n",
       "   (ln_1): LayerNorm()\n",
       "   (attn): CausalSelfAttention(\n",
       "     (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
       "     (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "     (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (ln_2): LayerNorm()\n",
       "   (mlp): MLP(\n",
       "     (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "     (gelu): GELU(approximate='none')\n",
       "     (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "     (dropout): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'model.transformer.h.7.ln_1': LayerNorm(),\n",
       " 'model.transformer.h.7.attn': CausalSelfAttention(\n",
       "   (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
       "   (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "   (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'model.transformer.h.7.attn.c_attn': Linear(in_features=768, out_features=2304, bias=True),\n",
       " 'model.transformer.h.7.attn.c_proj': Linear(in_features=768, out_features=768, bias=True),\n",
       " 'model.transformer.h.7.attn.attn_dropout': Dropout(p=0.0, inplace=False),\n",
       " 'model.transformer.h.7.attn.resid_dropout': Dropout(p=0.0, inplace=False),\n",
       " 'model.transformer.h.7.ln_2': LayerNorm(),\n",
       " 'model.transformer.h.7.mlp': MLP(\n",
       "   (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "   (gelu): GELU(approximate='none')\n",
       "   (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "   (dropout): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'model.transformer.h.7.mlp.c_fc': Linear(in_features=768, out_features=3072, bias=True),\n",
       " 'model.transformer.h.7.mlp.gelu': GELU(approximate='none'),\n",
       " 'model.transformer.h.7.mlp.c_proj': Linear(in_features=3072, out_features=768, bias=True),\n",
       " 'model.transformer.h.7.mlp.dropout': Dropout(p=0.0, inplace=False),\n",
       " 'model.transformer.h.8': Block(\n",
       "   (ln_1): LayerNorm()\n",
       "   (attn): CausalSelfAttention(\n",
       "     (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
       "     (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "     (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (ln_2): LayerNorm()\n",
       "   (mlp): MLP(\n",
       "     (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "     (gelu): GELU(approximate='none')\n",
       "     (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "     (dropout): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'model.transformer.h.8.ln_1': LayerNorm(),\n",
       " 'model.transformer.h.8.attn': CausalSelfAttention(\n",
       "   (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
       "   (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "   (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'model.transformer.h.8.attn.c_attn': Linear(in_features=768, out_features=2304, bias=True),\n",
       " 'model.transformer.h.8.attn.c_proj': Linear(in_features=768, out_features=768, bias=True),\n",
       " 'model.transformer.h.8.attn.attn_dropout': Dropout(p=0.0, inplace=False),\n",
       " 'model.transformer.h.8.attn.resid_dropout': Dropout(p=0.0, inplace=False),\n",
       " 'model.transformer.h.8.ln_2': LayerNorm(),\n",
       " 'model.transformer.h.8.mlp': MLP(\n",
       "   (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "   (gelu): GELU(approximate='none')\n",
       "   (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "   (dropout): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'model.transformer.h.8.mlp.c_fc': Linear(in_features=768, out_features=3072, bias=True),\n",
       " 'model.transformer.h.8.mlp.gelu': GELU(approximate='none'),\n",
       " 'model.transformer.h.8.mlp.c_proj': Linear(in_features=3072, out_features=768, bias=True),\n",
       " 'model.transformer.h.8.mlp.dropout': Dropout(p=0.0, inplace=False),\n",
       " 'model.transformer.h.9': Block(\n",
       "   (ln_1): LayerNorm()\n",
       "   (attn): CausalSelfAttention(\n",
       "     (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
       "     (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "     (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (ln_2): LayerNorm()\n",
       "   (mlp): MLP(\n",
       "     (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "     (gelu): GELU(approximate='none')\n",
       "     (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "     (dropout): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'model.transformer.h.9.ln_1': LayerNorm(),\n",
       " 'model.transformer.h.9.attn': CausalSelfAttention(\n",
       "   (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
       "   (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "   (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'model.transformer.h.9.attn.c_attn': Linear(in_features=768, out_features=2304, bias=True),\n",
       " 'model.transformer.h.9.attn.c_proj': Linear(in_features=768, out_features=768, bias=True),\n",
       " 'model.transformer.h.9.attn.attn_dropout': Dropout(p=0.0, inplace=False),\n",
       " 'model.transformer.h.9.attn.resid_dropout': Dropout(p=0.0, inplace=False),\n",
       " 'model.transformer.h.9.ln_2': LayerNorm(),\n",
       " 'model.transformer.h.9.mlp': MLP(\n",
       "   (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "   (gelu): GELU(approximate='none')\n",
       "   (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "   (dropout): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'model.transformer.h.9.mlp.c_fc': Linear(in_features=768, out_features=3072, bias=True),\n",
       " 'model.transformer.h.9.mlp.gelu': GELU(approximate='none'),\n",
       " 'model.transformer.h.9.mlp.c_proj': Linear(in_features=3072, out_features=768, bias=True),\n",
       " 'model.transformer.h.9.mlp.dropout': Dropout(p=0.0, inplace=False),\n",
       " 'model.transformer.h.10': Block(\n",
       "   (ln_1): LayerNorm()\n",
       "   (attn): CausalSelfAttention(\n",
       "     (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
       "     (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "     (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (ln_2): LayerNorm()\n",
       "   (mlp): MLP(\n",
       "     (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "     (gelu): GELU(approximate='none')\n",
       "     (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "     (dropout): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'model.transformer.h.10.ln_1': LayerNorm(),\n",
       " 'model.transformer.h.10.attn': CausalSelfAttention(\n",
       "   (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
       "   (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "   (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'model.transformer.h.10.attn.c_attn': Linear(in_features=768, out_features=2304, bias=True),\n",
       " 'model.transformer.h.10.attn.c_proj': Linear(in_features=768, out_features=768, bias=True),\n",
       " 'model.transformer.h.10.attn.attn_dropout': Dropout(p=0.0, inplace=False),\n",
       " 'model.transformer.h.10.attn.resid_dropout': Dropout(p=0.0, inplace=False),\n",
       " 'model.transformer.h.10.ln_2': LayerNorm(),\n",
       " 'model.transformer.h.10.mlp': MLP(\n",
       "   (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "   (gelu): GELU(approximate='none')\n",
       "   (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "   (dropout): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'model.transformer.h.10.mlp.c_fc': Linear(in_features=768, out_features=3072, bias=True),\n",
       " 'model.transformer.h.10.mlp.gelu': GELU(approximate='none'),\n",
       " 'model.transformer.h.10.mlp.c_proj': Linear(in_features=3072, out_features=768, bias=True),\n",
       " 'model.transformer.h.10.mlp.dropout': Dropout(p=0.0, inplace=False),\n",
       " 'model.transformer.h.11': Block(\n",
       "   (ln_1): LayerNorm()\n",
       "   (attn): CausalSelfAttention(\n",
       "     (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
       "     (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "     (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (ln_2): LayerNorm()\n",
       "   (mlp): MLP(\n",
       "     (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "     (gelu): GELU(approximate='none')\n",
       "     (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "     (dropout): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'model.transformer.h.11.ln_1': LayerNorm(),\n",
       " 'model.transformer.h.11.attn': CausalSelfAttention(\n",
       "   (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
       "   (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "   (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'model.transformer.h.11.attn.c_attn': Linear(in_features=768, out_features=2304, bias=True),\n",
       " 'model.transformer.h.11.attn.c_proj': Linear(in_features=768, out_features=768, bias=True),\n",
       " 'model.transformer.h.11.attn.attn_dropout': Dropout(p=0.0, inplace=False),\n",
       " 'model.transformer.h.11.attn.resid_dropout': Dropout(p=0.0, inplace=False),\n",
       " 'model.transformer.h.11.ln_2': LayerNorm(),\n",
       " 'model.transformer.h.11.mlp': MLP(\n",
       "   (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "   (gelu): GELU(approximate='none')\n",
       "   (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "   (dropout): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'model.transformer.h.11.mlp.c_fc': Linear(in_features=768, out_features=3072, bias=True),\n",
       " 'model.transformer.h.11.mlp.gelu': GELU(approximate='none'),\n",
       " 'model.transformer.h.11.mlp.c_proj': Linear(in_features=3072, out_features=768, bias=True),\n",
       " 'model.transformer.h.11.mlp.dropout': Dropout(p=0.0, inplace=False),\n",
       " 'model.transformer.ln_f': LayerNorm(),\n",
       " 'model.lm_head': Linear(in_features=768, out_features=50257, bias=False)}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "named_modules = {k:v for k,v in foundation.named_modules()}\n",
    "named_modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6683cc51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.transformer.h.0.attn.c_attn\n",
      "model.transformer.h.0.attn.c_proj\n",
      "model.transformer.h.0.mlp.c_fc\n",
      "model.transformer.h.0.mlp.c_proj\n",
      "model.transformer.h.1.attn.c_attn\n",
      "model.transformer.h.1.attn.c_proj\n",
      "model.transformer.h.1.mlp.c_fc\n",
      "model.transformer.h.1.mlp.c_proj\n",
      "model.transformer.h.2.attn.c_attn\n",
      "model.transformer.h.2.attn.c_proj\n",
      "model.transformer.h.2.mlp.c_fc\n",
      "model.transformer.h.2.mlp.c_proj\n",
      "model.transformer.h.3.attn.c_attn\n",
      "model.transformer.h.3.attn.c_proj\n",
      "model.transformer.h.3.mlp.c_fc\n",
      "model.transformer.h.3.mlp.c_proj\n",
      "model.transformer.h.4.attn.c_attn\n",
      "model.transformer.h.4.attn.c_proj\n",
      "model.transformer.h.4.mlp.c_fc\n",
      "model.transformer.h.4.mlp.c_proj\n",
      "model.transformer.h.5.attn.c_attn\n",
      "model.transformer.h.5.attn.c_proj\n",
      "model.transformer.h.5.mlp.c_fc\n",
      "model.transformer.h.5.mlp.c_proj\n",
      "model.transformer.h.6.attn.c_attn\n",
      "model.transformer.h.6.attn.c_proj\n",
      "model.transformer.h.6.mlp.c_fc\n",
      "model.transformer.h.6.mlp.c_proj\n",
      "model.transformer.h.7.attn.c_attn\n",
      "model.transformer.h.7.attn.c_proj\n",
      "model.transformer.h.7.mlp.c_fc\n",
      "model.transformer.h.7.mlp.c_proj\n",
      "model.transformer.h.8.attn.c_attn\n",
      "model.transformer.h.8.attn.c_proj\n",
      "model.transformer.h.8.mlp.c_fc\n",
      "model.transformer.h.8.mlp.c_proj\n",
      "model.transformer.h.9.attn.c_attn\n",
      "model.transformer.h.9.attn.c_proj\n",
      "model.transformer.h.9.mlp.c_fc\n",
      "model.transformer.h.9.mlp.c_proj\n",
      "model.transformer.h.10.attn.c_attn\n",
      "model.transformer.h.10.attn.c_proj\n",
      "model.transformer.h.10.mlp.c_fc\n",
      "model.transformer.h.10.mlp.c_proj\n",
      "model.transformer.h.11.attn.c_attn\n",
      "model.transformer.h.11.attn.c_proj\n",
      "model.transformer.h.11.mlp.c_fc\n",
      "model.transformer.h.11.mlp.c_proj\n",
      "model.lm_head\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "[print(n) for n,m in named_modules.items() if isinstance(m, nn.Linear)]\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab09f6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "model\n",
      "model.transformer\n",
      "model.transformer.wte\n",
      "model.transformer.wpe\n",
      "model.transformer.drop\n",
      "model.transformer.h\n",
      "model.transformer.h.0\n",
      "model.transformer.h.0.ln_1\n",
      "model.transformer.h.0.attn\n",
      "model.transformer.h.0.attn.c_attn\n",
      "model.transformer.h.0.attn.c_proj\n",
      "model.transformer.h.0.attn.attn_dropout\n",
      "model.transformer.h.0.attn.resid_dropout\n",
      "model.transformer.h.0.ln_2\n",
      "model.transformer.h.0.mlp\n",
      "model.transformer.h.0.mlp.c_fc\n",
      "model.transformer.h.0.mlp.gelu\n",
      "model.transformer.h.0.mlp.c_proj\n",
      "model.transformer.h.0.mlp.dropout\n",
      "model.transformer.h.1\n",
      "model.transformer.h.1.ln_1\n",
      "model.transformer.h.1.attn\n",
      "model.transformer.h.1.attn.c_attn\n",
      "model.transformer.h.1.attn.c_proj\n",
      "model.transformer.h.1.attn.attn_dropout\n",
      "model.transformer.h.1.attn.resid_dropout\n",
      "model.transformer.h.1.ln_2\n",
      "model.transformer.h.1.mlp\n",
      "model.transformer.h.1.mlp.c_fc\n",
      "model.transformer.h.1.mlp.gelu\n",
      "model.transformer.h.1.mlp.c_proj\n",
      "model.transformer.h.1.mlp.dropout\n",
      "model.transformer.h.2\n",
      "model.transformer.h.2.ln_1\n",
      "model.transformer.h.2.attn\n",
      "model.transformer.h.2.attn.c_attn\n",
      "model.transformer.h.2.attn.c_proj\n",
      "model.transformer.h.2.attn.attn_dropout\n",
      "model.transformer.h.2.attn.resid_dropout\n",
      "model.transformer.h.2.ln_2\n",
      "model.transformer.h.2.mlp\n",
      "model.transformer.h.2.mlp.c_fc\n",
      "model.transformer.h.2.mlp.gelu\n",
      "model.transformer.h.2.mlp.c_proj\n",
      "model.transformer.h.2.mlp.dropout\n",
      "model.transformer.h.3\n",
      "model.transformer.h.3.ln_1\n",
      "model.transformer.h.3.attn\n",
      "model.transformer.h.3.attn.c_attn\n",
      "model.transformer.h.3.attn.c_proj\n",
      "model.transformer.h.3.attn.attn_dropout\n",
      "model.transformer.h.3.attn.resid_dropout\n",
      "model.transformer.h.3.ln_2\n",
      "model.transformer.h.3.mlp\n",
      "model.transformer.h.3.mlp.c_fc\n",
      "model.transformer.h.3.mlp.gelu\n",
      "model.transformer.h.3.mlp.c_proj\n",
      "model.transformer.h.3.mlp.dropout\n",
      "model.transformer.h.4\n",
      "model.transformer.h.4.ln_1\n",
      "model.transformer.h.4.attn\n",
      "model.transformer.h.4.attn.c_attn\n",
      "model.transformer.h.4.attn.c_proj\n",
      "model.transformer.h.4.attn.attn_dropout\n",
      "model.transformer.h.4.attn.resid_dropout\n",
      "model.transformer.h.4.ln_2\n",
      "model.transformer.h.4.mlp\n",
      "model.transformer.h.4.mlp.c_fc\n",
      "model.transformer.h.4.mlp.gelu\n",
      "model.transformer.h.4.mlp.c_proj\n",
      "model.transformer.h.4.mlp.dropout\n",
      "model.transformer.h.5\n",
      "model.transformer.h.5.ln_1\n",
      "model.transformer.h.5.attn\n",
      "model.transformer.h.5.attn.c_attn\n",
      "model.transformer.h.5.attn.c_proj\n",
      "model.transformer.h.5.attn.attn_dropout\n",
      "model.transformer.h.5.attn.resid_dropout\n",
      "model.transformer.h.5.ln_2\n",
      "model.transformer.h.5.mlp\n",
      "model.transformer.h.5.mlp.c_fc\n",
      "model.transformer.h.5.mlp.gelu\n",
      "model.transformer.h.5.mlp.c_proj\n",
      "model.transformer.h.5.mlp.dropout\n",
      "model.transformer.h.6\n",
      "model.transformer.h.6.ln_1\n",
      "model.transformer.h.6.attn\n",
      "model.transformer.h.6.attn.c_attn\n",
      "model.transformer.h.6.attn.c_proj\n",
      "model.transformer.h.6.attn.attn_dropout\n",
      "model.transformer.h.6.attn.resid_dropout\n",
      "model.transformer.h.6.ln_2\n",
      "model.transformer.h.6.mlp\n",
      "model.transformer.h.6.mlp.c_fc\n",
      "model.transformer.h.6.mlp.gelu\n",
      "model.transformer.h.6.mlp.c_proj\n",
      "model.transformer.h.6.mlp.dropout\n",
      "model.transformer.h.7\n",
      "model.transformer.h.7.ln_1\n",
      "model.transformer.h.7.attn\n",
      "model.transformer.h.7.attn.c_attn\n",
      "model.transformer.h.7.attn.c_proj\n",
      "model.transformer.h.7.attn.attn_dropout\n",
      "model.transformer.h.7.attn.resid_dropout\n",
      "model.transformer.h.7.ln_2\n",
      "model.transformer.h.7.mlp\n",
      "model.transformer.h.7.mlp.c_fc\n",
      "model.transformer.h.7.mlp.gelu\n",
      "model.transformer.h.7.mlp.c_proj\n",
      "model.transformer.h.7.mlp.dropout\n",
      "model.transformer.h.8\n",
      "model.transformer.h.8.ln_1\n",
      "model.transformer.h.8.attn\n",
      "model.transformer.h.8.attn.c_attn\n",
      "model.transformer.h.8.attn.c_proj\n",
      "model.transformer.h.8.attn.attn_dropout\n",
      "model.transformer.h.8.attn.resid_dropout\n",
      "model.transformer.h.8.ln_2\n",
      "model.transformer.h.8.mlp\n",
      "model.transformer.h.8.mlp.c_fc\n",
      "model.transformer.h.8.mlp.gelu\n",
      "model.transformer.h.8.mlp.c_proj\n",
      "model.transformer.h.8.mlp.dropout\n",
      "model.transformer.h.9\n",
      "model.transformer.h.9.ln_1\n",
      "model.transformer.h.9.attn\n",
      "model.transformer.h.9.attn.c_attn\n",
      "model.transformer.h.9.attn.c_proj\n",
      "model.transformer.h.9.attn.attn_dropout\n",
      "model.transformer.h.9.attn.resid_dropout\n",
      "model.transformer.h.9.ln_2\n",
      "model.transformer.h.9.mlp\n",
      "model.transformer.h.9.mlp.c_fc\n",
      "model.transformer.h.9.mlp.gelu\n",
      "model.transformer.h.9.mlp.c_proj\n",
      "model.transformer.h.9.mlp.dropout\n",
      "model.transformer.h.10\n",
      "model.transformer.h.10.ln_1\n",
      "model.transformer.h.10.attn\n",
      "model.transformer.h.10.attn.c_attn\n",
      "model.transformer.h.10.attn.c_proj\n",
      "model.transformer.h.10.attn.attn_dropout\n",
      "model.transformer.h.10.attn.resid_dropout\n",
      "model.transformer.h.10.ln_2\n",
      "model.transformer.h.10.mlp\n",
      "model.transformer.h.10.mlp.c_fc\n",
      "model.transformer.h.10.mlp.gelu\n",
      "model.transformer.h.10.mlp.c_proj\n",
      "model.transformer.h.10.mlp.dropout\n",
      "model.transformer.h.11\n",
      "model.transformer.h.11.ln_1\n",
      "model.transformer.h.11.attn\n",
      "model.transformer.h.11.attn.c_attn\n",
      "model.transformer.h.11.attn.c_proj\n",
      "model.transformer.h.11.attn.attn_dropout\n",
      "model.transformer.h.11.attn.resid_dropout\n",
      "model.transformer.h.11.ln_2\n",
      "model.transformer.h.11.mlp\n",
      "model.transformer.h.11.mlp.c_fc\n",
      "model.transformer.h.11.mlp.gelu\n",
      "model.transformer.h.11.mlp.c_proj\n",
      "model.transformer.h.11.mlp.dropout\n",
      "model.transformer.ln_f\n",
      "model.lm_head\n"
     ]
    }
   ],
   "source": [
    "[print(m) for m in named_modules.keys()]\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "184f1a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: SyntaxWarning: invalid escape sequence '\\.'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\.'\n",
      "/var/folders/v0/dlhfhpj533b4_ldsv6gq0q8h0000gn/T/ipykernel_21503/300406542.py:3: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  re_attn_c_attn = '.*\\.attn\\.c_attn$'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model.transformer.h.0.attn.c_attn': Linear(in_features=768, out_features=2304, bias=True),\n",
       " 'model.transformer.h.1.attn.c_attn': Linear(in_features=768, out_features=2304, bias=True),\n",
       " 'model.transformer.h.2.attn.c_attn': Linear(in_features=768, out_features=2304, bias=True),\n",
       " 'model.transformer.h.3.attn.c_attn': Linear(in_features=768, out_features=2304, bias=True),\n",
       " 'model.transformer.h.4.attn.c_attn': Linear(in_features=768, out_features=2304, bias=True),\n",
       " 'model.transformer.h.5.attn.c_attn': Linear(in_features=768, out_features=2304, bias=True),\n",
       " 'model.transformer.h.6.attn.c_attn': Linear(in_features=768, out_features=2304, bias=True),\n",
       " 'model.transformer.h.7.attn.c_attn': Linear(in_features=768, out_features=2304, bias=True),\n",
       " 'model.transformer.h.8.attn.c_attn': Linear(in_features=768, out_features=2304, bias=True),\n",
       " 'model.transformer.h.9.attn.c_attn': Linear(in_features=768, out_features=2304, bias=True),\n",
       " 'model.transformer.h.10.attn.c_attn': Linear(in_features=768, out_features=2304, bias=True),\n",
       " 'model.transformer.h.11.attn.c_attn': Linear(in_features=768, out_features=2304, bias=True)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "re_attn_c_attn = '.*\\.attn\\.c_attn$'\n",
    "\n",
    "matches = {}\n",
    "for name, module in named_modules.items():\n",
    "    result = re.match(re_attn_c_attn, name)\n",
    "    if result is not None:\n",
    "        matches[name] = module\n",
    "    \n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "faf5e855",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_attn = matches[\"model.transformer.h.0.attn.c_attn\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2770719",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.rand((1,10,768))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3350f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_head: int = 12\n",
    "n_embd: int = 768\n",
    "\n",
    "B, T, C = x.size()\n",
    "\n",
    "q, k, v  = c_attn(x).split(n_embd, dim=2)\n",
    "headsk = k.view(B, T, n_head, C // n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "headsq = q.view(B, T, n_head, C // n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "headsv = v.view(B, T, n_head, C // n_head).transpose(1, 2) # (B, nh, T, hs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "218957f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split to just qkv\n",
    "to_q = nn.Linear(n_embd, n_embd)\n",
    "to_k = nn.Linear(n_embd, n_embd)\n",
    "to_v = nn.Linear(n_embd, n_embd)\n",
    "\n",
    "to_q.weight.data = c_attn.weight.data[0:n_embd,:]\n",
    "to_q.bias.data = c_attn.bias.data[0:n_embd]\n",
    "to_k.weight.data = c_attn.weight.data[n_embd:2*n_embd,:]\n",
    "to_k.bias.data = c_attn.bias.data[n_embd:2*n_embd]\n",
    "to_v.weight.data = c_attn.weight.data[2*n_embd:,:]\n",
    "to_v.bias.data = c_attn.bias.data[2*n_embd:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29546d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([to_q(x), to_k(x), to_v(x)], dim=-1) - c_attn(x)\n",
    "# validate =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c4f0b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]], grad_fn=<SubBackward0>),\n",
       " tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]], grad_fn=<SubBackward0>),\n",
       " tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]], grad_fn=<SubBackward0>))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_q(x) - q, to_k(x) - k, to_v(x) - v\n",
    "# validate =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "066ce55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split c_attn to qkv and heads\n",
    "total_head_linears = 3 * n_head\n",
    "head_dim = n_embd // n_head\n",
    "\n",
    "heads = {\n",
    "    \"q\": [],\n",
    "    \"k\": [],\n",
    "    \"v\": []\n",
    "}\n",
    "\n",
    "cur_ind = 0\n",
    "for head_type in heads:\n",
    "    for head_num in range(n_head):\n",
    "        split_weight = c_attn.weight.data[cur_ind:cur_ind+head_dim,:]  # [out_dim, in_dim] -> [head_dim, in_dim]\n",
    "        split_bias = c_attn.bias.data[cur_ind:cur_ind+head_dim]  # [out_dim] -> [head_dim]\n",
    "        new_linear = nn.Linear(n_embd, head_dim)\n",
    "        new_linear.weight.data = split_weight\n",
    "        new_linear.bias.data = split_bias\n",
    "        heads[head_type].append(new_linear)\n",
    "        cur_ind += head_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c333785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 768])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# get q\n",
    "all_q = []\n",
    "for qhead in heads[\"q\"]:\n",
    "    one_head_q = qhead(x)\n",
    "    all_q.append(one_head_q)\n",
    "\n",
    "each_head_q = torch.cat(all_q, dim=-1)\n",
    "each_head_q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7fed28fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "each_head_q - q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2a6dc41b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 2304])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# get q\n",
    "all_attn = []\n",
    "for qhead in heads[\"q\"]:\n",
    "    one_head_q = qhead(x)\n",
    "    all_attn.append(one_head_q)\n",
    "\n",
    "for qhead in heads[\"k\"]:\n",
    "    one_head_k = qhead(x)\n",
    "    all_attn.append(one_head_k)\n",
    "\n",
    "for qhead in heads[\"v\"]:\n",
    "    one_head_v = qhead(x)\n",
    "    all_attn.append(one_head_v)\n",
    "\n",
    "each_head_attn = torch.cat(all_attn, dim=-1)\n",
    "each_head_attn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5f3720c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "each_head_attn - c_attn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a32f03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2ffaec2",
   "metadata": {},
   "source": [
    "# conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a48cb2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting config.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile config.yaml\n",
    "weight_types:\n",
    "    attn_c_attn:\n",
    "        pattern: '.*\\.attn\\.c_attn$'\n",
    "        split: false  # qkv, heads\n",
    "        qkv_order: qkv  # string\n",
    "        n_head: 12\n",
    "    attn_c_proj: \n",
    "        pattern: '.*\\.attn\\.c_proj$'\n",
    "    mlp_c_fc: \n",
    "        pattern: '.*\\.mlp\\.c_fc$'\n",
    "    mlp_c_proj: \n",
    "        pattern: '.*\\.mlp\\.c_proj$'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bff48a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "with open(\"config.yaml\") as f:\n",
    "    cfg = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ca55c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'.*\\\\.attn\\\\.c_attn$'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 33), match='model.transformer.h.0.attn.c_attn'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "patt = cfg['weight_types'][\"attn_c_attn\"][\"pattern\"]\n",
    "print(repr(patt))\n",
    "\n",
    "re.match(patt, \"model.transformer.h.0.attn.c_attn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c394a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "from torch.nn import init\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "class SplitLinear(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.splits: nn.Module|nn.Linear = []\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        outs = []\n",
    "        for split in self.splits:\n",
    "            outs = split(x)\n",
    "        return torch.cat(outs, dim=-1)\n",
    "\n",
    "class ShareLinear(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features: int,\n",
    "        basis_features: int,\n",
    "        out_features: int,\n",
    "        bias: bool = True,\n",
    "        device=None,\n",
    "        dtype=None\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.basis = nn.Parameter(\n",
    "            torch.empty(basis_features, in_features, device=device, dtype=dtype)\n",
    "        )\n",
    "        self.coefficient = nn.Parameter(\n",
    "            torch.empty(out_features, basis_features, device=device, dtype=dtype)\n",
    "        )\n",
    "        self.bias = nn.Parameter(\n",
    "            torch.empty(out_features, device=device, dtype=dtype)\n",
    "        )\n",
    "        # self.original = nn.Parameter(\n",
    "        #     torch.empty(basis_features, in_features, device=device, dtype=dtype)\n",
    "        # )\n",
    "    \n",
    "    \n",
    "    def initialize_parameters(self) -> None:\n",
    "        # from nn.Linear\n",
    "        init.kaiming_uniform_(self.basis, a=math.sqrt(5))\n",
    "        init.kaiming_uniform_(self.coefficient, a=math.sqrt(5))\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = init._calculate_fan_in_and_fan_out(self.weight)\n",
    "            bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n",
    "            init.uniform_(self.bias, -bound, bound)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        b = F.linear(x, self.basis)\n",
    "        out = F.linear(b, self.coefficient, self.bias)\n",
    "        return out\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87107075",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "class SplitLinearWrapper:\n",
    "    def __init__(self, model, config):\n",
    "        self.model = model\n",
    "        self.config = config\n",
    "\n",
    "        self.weight_types = defaultdict(list)\n",
    "\n",
    "        named_modules = {k:v for k,v in model.named_modules()}\n",
    "\n",
    "        for name, module in named_modules:\n",
    "            for wtype, wtype_cfg in self.config[\"weight_types\"].items():\n",
    "                if re.match(wtype_cfg[\"pattern\"], name) is not None:\n",
    "                    name_parts = name.split(\".\")\n",
    "                    parent_name = \".\".join(name_parts[:-1])\n",
    "                    parent = named_modules[parent_name]\n",
    "                    list_id = None\n",
    "                    if name_parts[-1].isdigit():\n",
    "                        list_id = int(name_parts[-1])\n",
    "\n",
    "                    self.weight_types[wtype].append({\n",
    "                        \"name\": name,\n",
    "                        \"module\": module,\n",
    "                        \"parent\": parent,\n",
    "                        \"list_id\": list_id,\n",
    "                        \"last_name_part\": name_parts[-1],\n",
    "                    })\n",
    "        \n",
    "        for wtype, list_wt_modules in self.weight_types.items():\n",
    "            wtype_cfg = self.config[\"weight_types\"][wtype]\n",
    "            for wt_dict in list_wt_modules:\n",
    "                module = wt_dict[\"module\"]\n",
    "                name = wt_dict[\"name\"]\n",
    "                if wtype_cfg[\"split\"] == \"qkv\":\n",
    "                    split_linear = SplitLinear()\n",
    "                    in_feats = module.in_features\n",
    "                    out_feats = module.out_features\n",
    "                    assert out_feats % 3 == 0\n",
    "                    qkv_feats = out_feats // 3 \n",
    "                    \n",
    "                    to_q = nn.Linear(in_feats, qkv_feats)\n",
    "                    to_k = nn.Linear(in_feats, qkv_feats)\n",
    "                    to_v = nn.Linear(in_feats, qkv_feats)\n",
    "\n",
    "                    to_q.weight.data = module.weight.data[0:qkv_feats,:]\n",
    "                    to_q.bias.data = module.bias.data[0:qkv_feats]\n",
    "                    to_k.weight.data = module.weight.data[qkv_feats:2*qkv_feats,:]\n",
    "                    to_k.bias.data = module.bias.data[qkv_feats:2*qkv_feats]\n",
    "                    to_v.weight.data = module.weight.data[2*qkv_feats:,:]\n",
    "                    to_v.bias.data = module.bias.data[2*qkv_feats:]\n",
    "\n",
    "                    qkv = {\n",
    "                        \"q\": to_q,\n",
    "                        \"k\": to_k,\n",
    "                        \"v\": to_v,\n",
    "                    }\n",
    "                    for n in wt_dict[\"qkv_order\"]:\n",
    "                        split_linear.splits.append(qkv[n])\n",
    "                    setattr(wt_dict[\"parent\"], wt_dict[\"last_name_part\"], split_linear)\n",
    "\n",
    "                elif wtype_cfg[\"split\"] == \"heads\":\n",
    "                    split_linear = SplitLinear()\n",
    "                    in_feats = module.in_features\n",
    "                    out_feats = module.out_features\n",
    "                    assert out_feats % 3 == 0\n",
    "                    qkv_feats = out_feats // 3 \n",
    "                    n_heads = wtype_cfg[\"n_head\"]\n",
    "\n",
    "                    head_dim = qkv_feats // n_heads\n",
    "\n",
    "                    heads = {\n",
    "                        \"q\": [],\n",
    "                        \"k\": [],\n",
    "                        \"v\": []\n",
    "                    }\n",
    "\n",
    "                    cur_ind = 0\n",
    "                    for head_type in heads:\n",
    "                        for head_num in range(n_heads):\n",
    "                            split_weight = module.weight.data[cur_ind:cur_ind+head_dim,:]  # [out_dim, in_dim] -> [head_dim, in_dim]\n",
    "                            split_bias = module.bias.data[cur_ind:cur_ind+head_dim]  # [out_dim] -> [head_dim]\n",
    "                            new_linear = nn.Linear(in_feats, head_dim)\n",
    "                            new_linear.weight.data = split_weight\n",
    "                            new_linear.bias.data = split_bias\n",
    "                            heads[head_type].append(new_linear)\n",
    "                            cur_ind += head_dim\n",
    "                    \n",
    "                    for n in wt_dict[\"qkv_order\"]:\n",
    "                        for head in heads[n]:\n",
    "                            split_linear.splits.append(head)\n",
    "                    \n",
    "                    setattr(wt_dict[\"parent\"], wt_dict[\"last_name_part\"], split_linear)\n",
    "\n",
    "                else: # no split\n",
    "                    split_linear = SplitLinear()\n",
    "                    in_linear = nn.Linear(module.in_features, module.out_features, bias=module.bias)\n",
    "                    in_linear.weight.data = module.weight.data\n",
    "                    if module.bias:\n",
    "                        in_linear.bias.data = module.bias.data\n",
    "                    split_linear.splits.append(in_linear)\n",
    "                    setattr(wt_dict[\"parent\"], wt_dict[\"last_name_part\"], split_linear)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcfaa75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b2a5bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9a7bea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d06272ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative ||Xw Xw^T - I||: 3.8652837019981234e-07\n",
      "Whiten+SVD rank-30 relative output error: 0.24934543669223785\n",
      "Max |Y_hat - Y_hat2|: 1.52587890625e-05\n",
      "Plain SVD rank-30 relative output error: 0.2619509994983673\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# --- toy setup: one Linear layer ---\n",
    "in_dim  = 64\n",
    "out_dim = 48\n",
    "n_calib = 512   # \"calibration\" samples (columns)\n",
    "\n",
    "W = torch.randn(out_dim, in_dim)          # weight matrix (out_dim x in_dim)\n",
    "X = torch.randn(in_dim, n_calib)          # activations (in_dim x n_calib)\n",
    "\n",
    "# Original output\n",
    "Y = W @ X                                  # (out_dim x n_calib)\n",
    "\n",
    "# --- Cholesky-based whitening on X ---\n",
    "# Gram / (unnormalized covariance) of features: G = X X^T\n",
    "G = X @ X.T                                # (in_dim x in_dim)\n",
    "\n",
    "eps = 1e-5\n",
    "S = torch.linalg.cholesky(G + eps * torch.eye(in_dim))  # lower-triangular, G  S S^T\n",
    "\n",
    "# Whitened activations: Xw = S^{-1} X  (do NOT form S^{-1}; solve triangular system)\n",
    "Xw = torch.linalg.solve_triangular(S, X, upper=False)   # solves S * Xw = X\n",
    "\n",
    "# Check: Xw Xw^T  I  (up to eps and finite-sample effects)\n",
    "I = torch.eye(in_dim)\n",
    "whiten_error = (Xw @ Xw.T - I).norm() / I.norm()\n",
    "print(\"Relative ||Xw Xw^T - I||:\", float(whiten_error))\n",
    "\n",
    "# --- \"whiten-then-SVD\" compression: SVD on (W S) ---\n",
    "WS = W @ S                                  # (out_dim x in_dim)\n",
    "\n",
    "U, sig, Vh = torch.linalg.svd(WS, full_matrices=False)  # WS = U diag(sig) Vh\n",
    "\n",
    "k = 30  # target rank\n",
    "Uk  = U[:, :k]\n",
    "sigk = sig[:k]\n",
    "Vhk = Vh[:k, :]\n",
    "\n",
    "# Low-rank approx of WS:  WS_hat = Uk diag(sigk) Vhk\n",
    "WS_hat = (Uk * sigk) @ Vhk                  # (out_dim x in_dim)\n",
    "\n",
    "# Using the factorized form directly: Y_hat = WS_hat @ Xw\n",
    "Y_hat = WS_hat @ Xw\n",
    "\n",
    "rel_err = (Y_hat - Y).norm() / Y.norm()\n",
    "print(f\"Whiten+SVD rank-{k} relative output error:\", float(rel_err))\n",
    "\n",
    "# --- If you want an explicit compressed weight matrix W_hat (so Y_hat = W_hat @ X) ---\n",
    "# W_hat = WS_hat @ S^{-1}  (compute via triangular solve on transpose)\n",
    "# Since W_hat^T = S^{-T} WS_hat^T, solve: (S^T) * W_hat^T = WS_hat^T\n",
    "W_hat_T = torch.linalg.solve_triangular(S.T, WS_hat.T, upper=True)\n",
    "W_hat = W_hat_T.T\n",
    "\n",
    "Y_hat2 = W_hat @ X\n",
    "print(\"Max |Y_hat - Y_hat2|:\", float((Y_hat - Y_hat2).abs().max()))\n",
    "\n",
    "# --- Baseline: plain SVD on W (no whitening), for comparison ---\n",
    "U0, sig0, Vh0 = torch.linalg.svd(W, full_matrices=False)\n",
    "W_hat0 = (U0[:, :k] * sig0[:k]) @ Vh0[:k, :]\n",
    "Y_hat0 = W_hat0 @ X\n",
    "rel_err0 = (Y_hat0 - Y).norm() / Y.norm()\n",
    "print(f\"Plain SVD rank-{k} relative output error:\", float(rel_err0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a2d6a450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def compute_num_basis(\n",
    "    in_features: int, out_features: int, group_size: int, compression_ratio: int\n",
    ") -> int:\n",
    "    \"\"\"Compute number of basis vectors for target compression ratio.\"\"\"\n",
    "    total_original = in_features * out_features * group_size\n",
    "    # Compressed size: in_features * num_basis + num_basis * out_features * group_size\n",
    "    # Solving for num_basis given compression ratio\n",
    "    num_basis = int(\n",
    "        (total_original * compression_ratio) / (in_features + out_features * group_size)\n",
    "    )\n",
    "    return max(1, num_basis)\n",
    "\n",
    "compute_num_basis(100, 100, 1, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "68f34763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.5"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_num_basis(features: int, group_size: int, compression_ratio: int):\n",
    "    return (compression_ratio / (group_size + 1)) * features\n",
    "\n",
    "compute_num_basis(100,3,0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fe4e0dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_num_basis(nx, nf, group_strategy, compression_ratio):\n",
    "    total = nx * nf * group_strategy\n",
    "    num_basis = (total * compression_ratio) // (nx + nf * group_strategy)\n",
    "    return int(num_basis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1016b221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_num_basis(100,1000,1,0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a468b46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_num_basis(100,100,2,0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b95314",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_num_basis(100,100,1,0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4b2a46f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "A = torch.randn(3, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cacb421f",
   "metadata": {},
   "outputs": [],
   "source": [
    "U, S, Vh = torch.linalg.svd(A, full_matrices=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "efb34ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 3]), torch.Size([3]), torch.Size([3, 6]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U.shape, S.shape, Vh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e877d748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.4855e-07)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dist(A, U @ torch.diag(S) @ Vh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2996240b",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 2\n",
    "U_k = U[:,:k]\n",
    "S_k = S[:k]\n",
    "Vh_k = Vh[:k,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "488f27cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9563)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dist(A, U_k @ torch.diag(S_k) @ Vh_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0afccc34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(U @ torch.diag(S)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c318b7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = U @ torch.diag(S)\n",
    "C = Vh.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b42ad47c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.7860,  0.0633,  0.1788,  1.1016, -0.8312, -0.0152],\n",
       "        [-1.5974, -0.0145, -0.8706,  0.7203, -0.9590, -0.4208],\n",
       "        [ 0.0225, -1.4150,  0.2763,  0.8227,  0.5508, -0.1412]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B @ C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e91ae9ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.7860,  0.0633,  0.1788,  1.1016, -0.8312, -0.0152],\n",
       "        [-1.5974, -0.0145, -0.8706,  0.7203, -0.9590, -0.4208],\n",
       "        [ 0.0225, -1.4150,  0.2763,  0.8227,  0.5508, -0.1412]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c045f27f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5638d4fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.6527, -0.0723, -0.2512,  1.1536, -0.9690, -0.2129],\n",
       "        [-1.7942,  0.1856, -0.2354,  0.6435, -0.7555, -0.1286],\n",
       "        [-0.0109, -1.3810,  0.3842,  0.8097,  0.5853, -0.0915]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U_k @ torch.diag(S_k) @ Vh_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f05a7796",
   "metadata": {},
   "outputs": [],
   "source": [
    "B_k = B[:, :k]\n",
    "C_k = C[:k, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6adf3dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.6527, -0.0723, -0.2512,  1.1536, -0.9690, -0.2129],\n",
       "        [-1.7942,  0.1856, -0.2354,  0.6435, -0.7555, -0.1286],\n",
       "        [-0.0109, -1.3810,  0.3842,  0.8097,  0.5853, -0.0915]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B_k @ C_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1fa5c6df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dist(B_k @ C_k, U_k @ torch.diag(S_k) @ Vh_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6272797",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "562ab5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "A = torch.randn(7, 4)\n",
    "U, S, Vh = torch.linalg.svd(A, full_matrices=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8c97e57d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([7, 4]), torch.Size([4]), torch.Size([4, 4]))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U.shape, S.shape, Vh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17919d67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
