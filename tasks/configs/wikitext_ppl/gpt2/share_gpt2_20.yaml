# Basis Sharing Configuration for GPT-2 (20% compression)
model_args:
  model_type: "gpt2"
  model_name: "gpt2"
  group_size: 2
  compression_ratio: 20
  context_length: 1024
  stride: 1024

calibration_args:
  dataset_name: "wikitext"
  calibration_size: 256
  calib_batch_size: 1
  dataset_cache_dir: null

model_saving:
  save_compressed_model: true
  compressed_model_path: "./compressed_models/gpt2_20/wikitext"
