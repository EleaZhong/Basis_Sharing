{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea92b32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6d0d947",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bbml.foundations.gpt2 import GPT2Foundation, GPTConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65db2add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights from pretrained gpt: gpt2\n",
      "forcing vocab_size=50257, block_size=1024, bias=True\n",
      "number of parameters: 123.65M\n"
     ]
    }
   ],
   "source": [
    "foundation = GPT2Foundation(  # based on nanoGPT\n",
    "    GPTConfig(),\n",
    "    None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9aab61d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The quick brown fox jumps over it at the start of its fall to catch the'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foundation.run(foundation.input_model(text=\"The quick brown fox jumps over\", max_new_tokens=10)).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea72fd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b75c6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from enum import Enum\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import init\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "class SplitLinear(nn.Module):\n",
    "\n",
    "    def __init__(self, bias: bool, out_features: int | None = None, device=None, dtype=None):\n",
    "        super().__init__()\n",
    "        self.splits: nn.ModuleList = nn.ModuleList()\n",
    "\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(\n",
    "                torch.empty(out_features, device=device, dtype=dtype)\n",
    "            )\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        outs = []\n",
    "        for split in self.splits:\n",
    "            outs.append(split(x))\n",
    "        out = torch.cat(outs, dim=-1)\n",
    "        if self.bias is not None:\n",
    "            out = out + self.bias\n",
    "        return out\n",
    "    \n",
    "\n",
    "class ShareLinearState(str, Enum):\n",
    "    ORIGINAL = \"original\"  # Forward uses original weights\n",
    "    CALIBRATING = \"calibrating\"  # Forward uses original weights + tracks inputs\n",
    "    COMPRESSED = \"compressed\"  # Forward uses basis @ coefficient\n",
    "\n",
    "\n",
    "class ShareLinear(nn.Module):\n",
    "    state = ShareLinearState.ORIGINAL\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features: int,\n",
    "        basis_features: int,\n",
    "        out_features: int,\n",
    "        device=None,\n",
    "        dtype=None\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.basis_features = basis_features\n",
    "        self.out_features = out_features\n",
    "        \n",
    "        self.basis = nn.Parameter(\n",
    "            torch.empty(basis_features, in_features, device=device, dtype=dtype)\n",
    "        )\n",
    "        self.coefficient = nn.Parameter(\n",
    "            torch.empty(out_features, basis_features, device=device, dtype=dtype)\n",
    "        )\n",
    "        self.original = nn.Parameter(\n",
    "            torch.empty(out_features, in_features, device=device, dtype=dtype)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        if self.state == ShareLinearState.ORIGINAL:\n",
    "            return F.linear(x, self.original)\n",
    "\n",
    "        b = F.linear(x, self.basis)\n",
    "        out = F.linear(b, self.coefficient)\n",
    "        return out\n",
    "    \n",
    "    def extra_repr(self) -> str:\n",
    "        return f\"in={self.in_features}, basis={self.basis_features}, out={self.out_features}, state={self.state.value}\"\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07a3cba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "from typing import Literal\n",
    "from pydantic import BaseModel, model_validator\n",
    "\n",
    "class WeightConfig(BaseModel):\n",
    "    pattern: str\n",
    "    split: bool|Literal[\"qkv\", \"heads\"] = False\n",
    "    qkv_order: str = \"qkv\"\n",
    "    n_head: int|None = None\n",
    "\n",
    "    @model_validator(mode=\"after\")\n",
    "    def qkv_string(self):\n",
    "        if self.split:\n",
    "            if not self.qkv_order or set(self.qkv_order.lower()) != {\"q\", \"k\", \"v\"}:\n",
    "                raise ValueError(\"qkv_order must contain exactly 'q', 'k', and 'v' characters when split='qkv'\")\n",
    "        return self\n",
    "\n",
    "    @model_validator(mode=\"after\")\n",
    "    def validate_heads_split(self):\n",
    "        if self.split == \"heads\" and self.n_head is None:\n",
    "            raise ValueError(\"n_head must be set when split='heads'\")\n",
    "        return self\n",
    "\n",
    "class SplitConfig(BaseModel):\n",
    "    weight_types: dict[str, WeightConfig]\n",
    "    block_pattern: str|None = None\n",
    "\n",
    "\n",
    "\n",
    "class SplitLinearWrapper:\n",
    "    def __init__(self, model, config):\n",
    "        self.model = model\n",
    "        self.config = config\n",
    "\n",
    "    \n",
    "        self.original_weights = []\n",
    "\n",
    "        named_modules = {k:v for k,v in model.named_modules()}\n",
    "\n",
    "        for name, module in named_modules.items():\n",
    "            for wtype, wtype_cfg in self.config.weight_types.items():\n",
    "                if re.match(wtype_cfg.pattern, name) is not None:\n",
    "                    name_parts = name.split(\".\")\n",
    "                    parent_name = \".\".join(name_parts[:-1])\n",
    "                    parent = named_modules[parent_name]\n",
    "                    list_id = None\n",
    "                    if name_parts[-1].isdigit():\n",
    "                        list_id = int(name_parts[-1])\n",
    "                    \n",
    "                    layer_num = re.search(config.block_pattern, name).group(1)\n",
    "\n",
    "                    self.original_weights.append({\n",
    "                        \"name\": name,\n",
    "                        \"module\": module,\n",
    "                        \"parent\": parent,\n",
    "                        \"list_id\": list_id,\n",
    "                        \"last_name_part\": name_parts[-1],\n",
    "                        \"layer\": layer_num,\n",
    "                        \"weight_type\": wtype,\n",
    "                    })\n",
    "\n",
    "        self.all_basislinears = {}\n",
    "        self.weight_types = defaultdict(list)\n",
    "\n",
    "        for wt_dict in self.original_weights:\n",
    "            wtype_cfg = self.config.weight_types[wt_dict[\"weight_type\"]]\n",
    "            module = wt_dict[\"module\"]\n",
    "            name = wt_dict[\"name\"]\n",
    "            has_bias = module.bias is not None\n",
    "            in_feats = module.in_features\n",
    "            out_feats = module.out_features\n",
    "            split_linear = SplitLinear(bias=has_bias, out_features=out_feats)\n",
    "            if has_bias:\n",
    "                split_linear.bias.data = module.bias.data\n",
    "            setattr(wt_dict[\"parent\"], wt_dict[\"last_name_part\"], split_linear)\n",
    "\n",
    "            if wtype_cfg.split == \"qkv\" or wtype_cfg.split == \"heads\":\n",
    "                assert out_feats % 3 == 0\n",
    "                qkv_feats = out_feats // 3 \n",
    "            \n",
    "            if wtype_cfg.split == \"qkv\":\n",
    "                cur_ind = 0            \n",
    "                for qkv_part in wtype_cfg.qkv_order:\n",
    "                    to_part = ShareLinear(in_feats, in_feats, qkv_feats)    \n",
    "                    to_part.original.data = module.weight.data[cur_ind:cur_ind+qkv_feats,:]\n",
    "                    cur_ind += qkv_feats\n",
    "                    \n",
    "                    split_linear.splits.append(to_part)\n",
    "                    self.all_basislinears[f\"{name}.{qkv_part}\"] = to_part\n",
    "                \n",
    "            elif wtype_cfg.split == \"heads\":\n",
    "                n_heads = wtype_cfg.n_head\n",
    "                head_dim = qkv_feats // n_heads\n",
    "\n",
    "                cur_ind = 0\n",
    "                for qkv_part in wtype_cfg.qkv_order:\n",
    "                    for head_num in range(n_heads):\n",
    "                        to_head = ShareLinear(in_feats, in_feats, head_dim)\n",
    "                        to_head.original.data = module.weight.data[cur_ind:cur_ind+head_dim,:]  # [out_dim, in_dim] -> [head_dim, in_dim]\n",
    "                        cur_ind += head_dim\n",
    "\n",
    "                        split_linear.splits.append(to_head)\n",
    "                        self.all_basislinears[f\"{name}.{qkv_part}.{head_num}\"] = to_head\n",
    "                \n",
    "\n",
    "            else: # no split\n",
    "                in_linear = ShareLinear(in_feats, in_feats, out_feats)\n",
    "                in_linear.original.data = module.weight.data\n",
    "\n",
    "                split_linear.splits.append(in_linear)\n",
    "                self.all_basislinears[name] = in_linear\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "691bae32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting config.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile config.yaml\n",
    "weight_types:\n",
    "    attn_c_attn:\n",
    "        pattern: '.*\\.attn\\.c_attn$'\n",
    "        split: heads  # qkv, heads\n",
    "        qkv_order: qkv  # string\n",
    "        n_head: 12\n",
    "    attn_c_proj: \n",
    "        pattern: '.*\\.attn\\.c_proj$'\n",
    "    mlp_c_fc: \n",
    "        pattern: '.*\\.mlp\\.c_fc$'\n",
    "    mlp_c_proj: \n",
    "        pattern: '.*\\.mlp\\.c_proj$'\n",
    "\n",
    "block_pattern: 'h\\.(\\d+)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cfeb10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8286bb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "with open(\"config.yaml\") as f:\n",
    "    cfg = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ec166d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "facf4075",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitcfg = SplitConfig(**cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609a2521",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c0467a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapper = SplitLinearWrapper(foundation, splitcfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a2edd3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "VERIFICATION TEST: SplitLinear Weight Transfer\n",
      "============================================================\n",
      "\n",
      "[Test 1] Single Linear → SplitLinear (no split)\n",
      "  Max difference: 1.07e-06 ✅ PASS\n",
      "\n",
      "[Test 2] QKV Linear → SplitLinear (3-way split)\n",
      "  Max difference: 1.07e-06 ✅ PASS\n",
      "\n",
      "[Test 3] QKV Linear → SplitLinear (36-way head split)\n",
      "  Max difference: 1.07e-06 ✅ PASS\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# VERIFICATION TEST: Compare original vs wrapped model outputs\n",
    "# ============================================================================\n",
    "# This test verifies that SplitLinear correctly reproduces the original Linear behavior.\n",
    "# We use deterministic forward passes (not generation) to isolate weight transfer issues.\n",
    "\n",
    "import copy\n",
    "\n",
    "def verify_split_linear_equivalence():\n",
    "    \"\"\"Verify that splitting a linear layer preserves its forward pass behavior.\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"VERIFICATION TEST: SplitLinear Weight Transfer\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Test 1: Single Linear (no split)\n",
    "    print(\"\\n[Test 1] Single Linear → SplitLinear (no split)\")\n",
    "    torch.manual_seed(42)\n",
    "    original_linear = nn.Linear(768, 3072, bias=True)\n",
    "    x = torch.randn(2, 10, 768)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        expected = original_linear(x)\n",
    "    \n",
    "    # Create SplitLinear wrapper\n",
    "    split_linear = SplitLinear(bias=True, out_features=3072)\n",
    "    split_linear.bias.data = original_linear.bias.data.clone()\n",
    "    \n",
    "    share = ShareLinear(768, 768, 3072)\n",
    "    share.original.data = original_linear.weight.data.clone()\n",
    "    split_linear.splits.append(share)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        actual = split_linear(x)\n",
    "    \n",
    "    diff = (expected - actual).abs().max().item()\n",
    "    status = \"✅ PASS\" if diff < 1e-5 else \"❌ FAIL\"\n",
    "    print(f\"  Max difference: {diff:.2e} {status}\")\n",
    "    \n",
    "    # Test 2: QKV Split (3-way split)\n",
    "    print(\"\\n[Test 2] QKV Linear → SplitLinear (3-way split)\")\n",
    "    torch.manual_seed(42)\n",
    "    qkv_linear = nn.Linear(768, 2304, bias=True)  # 768 * 3 = 2304\n",
    "    x = torch.randn(2, 10, 768)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        expected = qkv_linear(x)\n",
    "    \n",
    "    split_linear = SplitLinear(bias=True, out_features=2304)\n",
    "    split_linear.bias.data = qkv_linear.bias.data.clone()\n",
    "    \n",
    "    # Split into Q, K, V (each 768)\n",
    "    for i, name in enumerate(['q', 'k', 'v']):\n",
    "        start = i * 768\n",
    "        end = start + 768\n",
    "        share = ShareLinear(768, 768, 768)\n",
    "        share.original.data = qkv_linear.weight.data[start:end, :].clone()\n",
    "        split_linear.splits.append(share)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        actual = split_linear(x)\n",
    "    \n",
    "    diff = (expected - actual).abs().max().item()\n",
    "    status = \"✅ PASS\" if diff < 1e-5 else \"❌ FAIL\"\n",
    "    print(f\"  Max difference: {diff:.2e} {status}\")\n",
    "    \n",
    "    # Test 3: Head Split (36-way split for 12 heads × 3 QKV)\n",
    "    print(\"\\n[Test 3] QKV Linear → SplitLinear (36-way head split)\")\n",
    "    torch.manual_seed(42)\n",
    "    qkv_linear = nn.Linear(768, 2304, bias=True)\n",
    "    x = torch.randn(2, 10, 768)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        expected = qkv_linear(x)\n",
    "    \n",
    "    split_linear = SplitLinear(bias=True, out_features=2304)\n",
    "    split_linear.bias.data = qkv_linear.bias.data.clone()\n",
    "    \n",
    "    n_heads = 12\n",
    "    head_dim = 64  # 768 / 12\n",
    "    cur_ind = 0\n",
    "    for qkv_part in ['q', 'k', 'v']:\n",
    "        for head_num in range(n_heads):\n",
    "            share = ShareLinear(768, 768, head_dim)\n",
    "            share.original.data = qkv_linear.weight.data[cur_ind:cur_ind+head_dim, :].clone()\n",
    "            cur_ind += head_dim\n",
    "            split_linear.splits.append(share)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        actual = split_linear(x)\n",
    "    \n",
    "    diff = (expected - actual).abs().max().item()\n",
    "    status = \"✅ PASS\" if diff < 1e-5 else \"❌ FAIL\"\n",
    "    print(f\"  Max difference: {diff:.2e} {status}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    return diff < 1e-5\n",
    "\n",
    "# Run the isolated verification tests\n",
    "all_passed = verify_split_linear_equivalence()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26e7c019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "FULL MODEL VERIFICATION: SplitLinearWrapper on GPT-2\n",
      "============================================================\n",
      "\n",
      "[1] Loading fresh GPT-2 model...\n",
      "loading weights from pretrained gpt: gpt2\n",
      "forcing vocab_size=50257, block_size=1024, bias=True\n",
      "number of parameters: 123.65M\n",
      "[2] Getting original model output...\n",
      "[3] Applying SplitLinearWrapper...\n",
      "[4] Getting wrapped model output...\n",
      "[5] Comparing outputs...\n",
      "\n",
      "  Original logits shape: torch.Size([1, 20, 50257])\n",
      "  Wrapped logits shape:  torch.Size([1, 20, 50257])\n",
      "  Max absolute difference:  1.14e-04\n",
      "  Mean absolute difference: 2.05e-05\n",
      "✅ PASS\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# FULL MODEL VERIFICATION: Test the SplitLinearWrapper on the actual model\n",
    "# ============================================================================\n",
    "# This creates a fresh model and compares outputs before/after wrapping\n",
    "\n",
    "def verify_full_model_wrapper():\n",
    "    \"\"\"Test the complete SplitLinearWrapper on GPT-2.\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"FULL MODEL VERIFICATION: SplitLinearWrapper on GPT-2\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Create a fresh model\n",
    "    print(\"\\n[1] Loading fresh GPT-2 model...\")\n",
    "    fresh_model = GPT2Foundation(GPTConfig(), None)\n",
    "    fresh_model.model.eval()\n",
    "    \n",
    "    # Create deterministic test input\n",
    "    torch.manual_seed(123)\n",
    "    test_input = torch.randint(0, 1000, (1, 20))\n",
    "    \n",
    "    # Get original output BEFORE wrapping\n",
    "    print(\"[2] Getting original model output...\")\n",
    "    with torch.no_grad():\n",
    "        original_output = fresh_model.model(test_input)\n",
    "        original_logits = original_output.clone() if isinstance(original_output, torch.Tensor) else original_output[0].clone()\n",
    "    \n",
    "    # Apply the wrapper\n",
    "    print(\"[3] Applying SplitLinearWrapper...\")\n",
    "    test_wrapper = SplitLinearWrapper(fresh_model, splitcfg)\n",
    "    fresh_model.model.eval()\n",
    "    \n",
    "    # Get output AFTER wrapping\n",
    "    print(\"[4] Getting wrapped model output...\")\n",
    "    with torch.no_grad():\n",
    "        wrapped_output = fresh_model.model(test_input)\n",
    "        wrapped_logits = wrapped_output if isinstance(wrapped_output, torch.Tensor) else wrapped_output[0]\n",
    "    \n",
    "    # Compare\n",
    "    print(\"[5] Comparing outputs...\")\n",
    "    diff = (original_logits - wrapped_logits).abs()\n",
    "    max_diff = diff.max().item()\n",
    "    mean_diff = diff.mean().item()\n",
    "    \n",
    "    print(f\"\\n  Original logits shape: {original_logits.shape}\")\n",
    "    print(f\"  Wrapped logits shape:  {wrapped_logits.shape}\")\n",
    "    print(f\"  Max absolute difference:  {max_diff:.2e}\")\n",
    "    print(f\"  Mean absolute difference: {mean_diff:.2e}\")\n",
    "    \n",
    "    passed = False\n",
    "    if torch.allclose(original_logits, wrapped_logits, rtol=1e-4, atol=1e-4):\n",
    "        print(\"✅ PASS\")\n",
    "        passed = True\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    return passed\n",
    "\n",
    "# Run full model verification\n",
    "# Note: This will load a new model, so it takes a moment\n",
    "model_test_passed = verify_full_model_wrapper()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ddd9b682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The quick brown fox jumps over the startled soldier and swallows him in a fierce'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foundation.run(foundation.input_model(text=\"The quick brown fox jumps over\", max_new_tokens=10)).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c30897b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model.transformer.h.0.attn.c_attn.q.0': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.0.attn.c_attn.q.1': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.0.attn.c_attn.q.2': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.0.attn.c_attn.q.3': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.0.attn.c_attn.q.4': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.0.attn.c_attn.q.5': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.0.attn.c_attn.q.6': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.0.attn.c_attn.q.7': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.0.attn.c_attn.q.8': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.0.attn.c_attn.q.9': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.0.attn.c_attn.q.10': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.0.attn.c_attn.q.11': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.0.attn.c_attn.k.0': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.0.attn.c_attn.k.1': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.0.attn.c_attn.k.2': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.0.attn.c_attn.k.3': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.0.attn.c_attn.k.4': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.0.attn.c_attn.k.5': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.0.attn.c_attn.k.6': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.0.attn.c_attn.k.7': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.0.attn.c_attn.k.8': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.0.attn.c_attn.k.9': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.0.attn.c_attn.k.10': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.0.attn.c_attn.k.11': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.0.attn.c_attn.v.0': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.0.attn.c_attn.v.1': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.0.attn.c_attn.v.2': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.0.attn.c_attn.v.3': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.0.attn.c_attn.v.4': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.0.attn.c_attn.v.5': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.0.attn.c_attn.v.6': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.0.attn.c_attn.v.7': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.0.attn.c_attn.v.8': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.0.attn.c_attn.v.9': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.0.attn.c_attn.v.10': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.0.attn.c_attn.v.11': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.0.attn.c_proj': ShareLinear(in=768, basis=768, out=768, state=original),\n",
       " 'model.transformer.h.0.mlp.c_fc': ShareLinear(in=768, basis=768, out=3072, state=original),\n",
       " 'model.transformer.h.0.mlp.c_proj': ShareLinear(in=3072, basis=3072, out=768, state=original),\n",
       " 'model.transformer.h.1.attn.c_attn.q.0': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.1.attn.c_attn.q.1': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.1.attn.c_attn.q.2': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.1.attn.c_attn.q.3': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.1.attn.c_attn.q.4': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.1.attn.c_attn.q.5': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.1.attn.c_attn.q.6': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.1.attn.c_attn.q.7': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.1.attn.c_attn.q.8': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.1.attn.c_attn.q.9': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.1.attn.c_attn.q.10': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.1.attn.c_attn.q.11': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.1.attn.c_attn.k.0': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.1.attn.c_attn.k.1': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.1.attn.c_attn.k.2': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.1.attn.c_attn.k.3': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.1.attn.c_attn.k.4': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.1.attn.c_attn.k.5': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.1.attn.c_attn.k.6': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.1.attn.c_attn.k.7': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.1.attn.c_attn.k.8': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.1.attn.c_attn.k.9': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.1.attn.c_attn.k.10': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.1.attn.c_attn.k.11': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.1.attn.c_attn.v.0': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.1.attn.c_attn.v.1': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.1.attn.c_attn.v.2': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.1.attn.c_attn.v.3': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.1.attn.c_attn.v.4': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.1.attn.c_attn.v.5': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.1.attn.c_attn.v.6': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.1.attn.c_attn.v.7': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.1.attn.c_attn.v.8': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.1.attn.c_attn.v.9': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.1.attn.c_attn.v.10': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.1.attn.c_attn.v.11': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.1.attn.c_proj': ShareLinear(in=768, basis=768, out=768, state=original),\n",
       " 'model.transformer.h.1.mlp.c_fc': ShareLinear(in=768, basis=768, out=3072, state=original),\n",
       " 'model.transformer.h.1.mlp.c_proj': ShareLinear(in=3072, basis=3072, out=768, state=original),\n",
       " 'model.transformer.h.2.attn.c_attn.q.0': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.2.attn.c_attn.q.1': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.2.attn.c_attn.q.2': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.2.attn.c_attn.q.3': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.2.attn.c_attn.q.4': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.2.attn.c_attn.q.5': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.2.attn.c_attn.q.6': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.2.attn.c_attn.q.7': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.2.attn.c_attn.q.8': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.2.attn.c_attn.q.9': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.2.attn.c_attn.q.10': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.2.attn.c_attn.q.11': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.2.attn.c_attn.k.0': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.2.attn.c_attn.k.1': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.2.attn.c_attn.k.2': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.2.attn.c_attn.k.3': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.2.attn.c_attn.k.4': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.2.attn.c_attn.k.5': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.2.attn.c_attn.k.6': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.2.attn.c_attn.k.7': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.2.attn.c_attn.k.8': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.2.attn.c_attn.k.9': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.2.attn.c_attn.k.10': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.2.attn.c_attn.k.11': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.2.attn.c_attn.v.0': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.2.attn.c_attn.v.1': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.2.attn.c_attn.v.2': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.2.attn.c_attn.v.3': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.2.attn.c_attn.v.4': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.2.attn.c_attn.v.5': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.2.attn.c_attn.v.6': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.2.attn.c_attn.v.7': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.2.attn.c_attn.v.8': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.2.attn.c_attn.v.9': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.2.attn.c_attn.v.10': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.2.attn.c_attn.v.11': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.2.attn.c_proj': ShareLinear(in=768, basis=768, out=768, state=original),\n",
       " 'model.transformer.h.2.mlp.c_fc': ShareLinear(in=768, basis=768, out=3072, state=original),\n",
       " 'model.transformer.h.2.mlp.c_proj': ShareLinear(in=3072, basis=3072, out=768, state=original),\n",
       " 'model.transformer.h.3.attn.c_attn.q.0': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.3.attn.c_attn.q.1': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.3.attn.c_attn.q.2': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.3.attn.c_attn.q.3': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.3.attn.c_attn.q.4': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.3.attn.c_attn.q.5': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.3.attn.c_attn.q.6': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.3.attn.c_attn.q.7': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.3.attn.c_attn.q.8': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.3.attn.c_attn.q.9': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.3.attn.c_attn.q.10': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.3.attn.c_attn.q.11': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.3.attn.c_attn.k.0': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.3.attn.c_attn.k.1': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.3.attn.c_attn.k.2': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.3.attn.c_attn.k.3': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.3.attn.c_attn.k.4': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.3.attn.c_attn.k.5': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.3.attn.c_attn.k.6': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.3.attn.c_attn.k.7': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.3.attn.c_attn.k.8': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.3.attn.c_attn.k.9': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.3.attn.c_attn.k.10': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.3.attn.c_attn.k.11': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.3.attn.c_attn.v.0': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.3.attn.c_attn.v.1': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.3.attn.c_attn.v.2': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.3.attn.c_attn.v.3': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.3.attn.c_attn.v.4': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.3.attn.c_attn.v.5': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.3.attn.c_attn.v.6': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.3.attn.c_attn.v.7': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.3.attn.c_attn.v.8': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.3.attn.c_attn.v.9': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.3.attn.c_attn.v.10': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.3.attn.c_attn.v.11': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.3.attn.c_proj': ShareLinear(in=768, basis=768, out=768, state=original),\n",
       " 'model.transformer.h.3.mlp.c_fc': ShareLinear(in=768, basis=768, out=3072, state=original),\n",
       " 'model.transformer.h.3.mlp.c_proj': ShareLinear(in=3072, basis=3072, out=768, state=original),\n",
       " 'model.transformer.h.4.attn.c_attn.q.0': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.4.attn.c_attn.q.1': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.4.attn.c_attn.q.2': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.4.attn.c_attn.q.3': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.4.attn.c_attn.q.4': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.4.attn.c_attn.q.5': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.4.attn.c_attn.q.6': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.4.attn.c_attn.q.7': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.4.attn.c_attn.q.8': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.4.attn.c_attn.q.9': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.4.attn.c_attn.q.10': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.4.attn.c_attn.q.11': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.4.attn.c_attn.k.0': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.4.attn.c_attn.k.1': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.4.attn.c_attn.k.2': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.4.attn.c_attn.k.3': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.4.attn.c_attn.k.4': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.4.attn.c_attn.k.5': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.4.attn.c_attn.k.6': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.4.attn.c_attn.k.7': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.4.attn.c_attn.k.8': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.4.attn.c_attn.k.9': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.4.attn.c_attn.k.10': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.4.attn.c_attn.k.11': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.4.attn.c_attn.v.0': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.4.attn.c_attn.v.1': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.4.attn.c_attn.v.2': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.4.attn.c_attn.v.3': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.4.attn.c_attn.v.4': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.4.attn.c_attn.v.5': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.4.attn.c_attn.v.6': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.4.attn.c_attn.v.7': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.4.attn.c_attn.v.8': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.4.attn.c_attn.v.9': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.4.attn.c_attn.v.10': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.4.attn.c_attn.v.11': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.4.attn.c_proj': ShareLinear(in=768, basis=768, out=768, state=original),\n",
       " 'model.transformer.h.4.mlp.c_fc': ShareLinear(in=768, basis=768, out=3072, state=original),\n",
       " 'model.transformer.h.4.mlp.c_proj': ShareLinear(in=3072, basis=3072, out=768, state=original),\n",
       " 'model.transformer.h.5.attn.c_attn.q.0': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.5.attn.c_attn.q.1': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.5.attn.c_attn.q.2': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.5.attn.c_attn.q.3': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.5.attn.c_attn.q.4': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.5.attn.c_attn.q.5': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.5.attn.c_attn.q.6': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.5.attn.c_attn.q.7': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.5.attn.c_attn.q.8': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.5.attn.c_attn.q.9': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.5.attn.c_attn.q.10': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.5.attn.c_attn.q.11': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.5.attn.c_attn.k.0': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.5.attn.c_attn.k.1': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.5.attn.c_attn.k.2': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.5.attn.c_attn.k.3': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.5.attn.c_attn.k.4': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.5.attn.c_attn.k.5': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.5.attn.c_attn.k.6': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.5.attn.c_attn.k.7': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.5.attn.c_attn.k.8': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.5.attn.c_attn.k.9': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.5.attn.c_attn.k.10': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.5.attn.c_attn.k.11': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.5.attn.c_attn.v.0': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.5.attn.c_attn.v.1': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.5.attn.c_attn.v.2': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.5.attn.c_attn.v.3': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.5.attn.c_attn.v.4': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.5.attn.c_attn.v.5': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.5.attn.c_attn.v.6': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.5.attn.c_attn.v.7': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.5.attn.c_attn.v.8': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.5.attn.c_attn.v.9': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.5.attn.c_attn.v.10': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.5.attn.c_attn.v.11': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.5.attn.c_proj': ShareLinear(in=768, basis=768, out=768, state=original),\n",
       " 'model.transformer.h.5.mlp.c_fc': ShareLinear(in=768, basis=768, out=3072, state=original),\n",
       " 'model.transformer.h.5.mlp.c_proj': ShareLinear(in=3072, basis=3072, out=768, state=original),\n",
       " 'model.transformer.h.6.attn.c_attn.q.0': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.6.attn.c_attn.q.1': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.6.attn.c_attn.q.2': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.6.attn.c_attn.q.3': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.6.attn.c_attn.q.4': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.6.attn.c_attn.q.5': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.6.attn.c_attn.q.6': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.6.attn.c_attn.q.7': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.6.attn.c_attn.q.8': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.6.attn.c_attn.q.9': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.6.attn.c_attn.q.10': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.6.attn.c_attn.q.11': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.6.attn.c_attn.k.0': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.6.attn.c_attn.k.1': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.6.attn.c_attn.k.2': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.6.attn.c_attn.k.3': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.6.attn.c_attn.k.4': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.6.attn.c_attn.k.5': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.6.attn.c_attn.k.6': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.6.attn.c_attn.k.7': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.6.attn.c_attn.k.8': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.6.attn.c_attn.k.9': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.6.attn.c_attn.k.10': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.6.attn.c_attn.k.11': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.6.attn.c_attn.v.0': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.6.attn.c_attn.v.1': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.6.attn.c_attn.v.2': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.6.attn.c_attn.v.3': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.6.attn.c_attn.v.4': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.6.attn.c_attn.v.5': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.6.attn.c_attn.v.6': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.6.attn.c_attn.v.7': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.6.attn.c_attn.v.8': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.6.attn.c_attn.v.9': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.6.attn.c_attn.v.10': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.6.attn.c_attn.v.11': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.6.attn.c_proj': ShareLinear(in=768, basis=768, out=768, state=original),\n",
       " 'model.transformer.h.6.mlp.c_fc': ShareLinear(in=768, basis=768, out=3072, state=original),\n",
       " 'model.transformer.h.6.mlp.c_proj': ShareLinear(in=3072, basis=3072, out=768, state=original),\n",
       " 'model.transformer.h.7.attn.c_attn.q.0': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.7.attn.c_attn.q.1': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.7.attn.c_attn.q.2': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.7.attn.c_attn.q.3': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.7.attn.c_attn.q.4': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.7.attn.c_attn.q.5': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.7.attn.c_attn.q.6': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.7.attn.c_attn.q.7': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.7.attn.c_attn.q.8': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.7.attn.c_attn.q.9': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.7.attn.c_attn.q.10': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.7.attn.c_attn.q.11': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.7.attn.c_attn.k.0': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.7.attn.c_attn.k.1': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.7.attn.c_attn.k.2': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.7.attn.c_attn.k.3': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.7.attn.c_attn.k.4': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.7.attn.c_attn.k.5': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.7.attn.c_attn.k.6': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.7.attn.c_attn.k.7': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.7.attn.c_attn.k.8': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.7.attn.c_attn.k.9': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.7.attn.c_attn.k.10': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.7.attn.c_attn.k.11': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.7.attn.c_attn.v.0': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.7.attn.c_attn.v.1': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.7.attn.c_attn.v.2': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.7.attn.c_attn.v.3': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.7.attn.c_attn.v.4': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.7.attn.c_attn.v.5': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.7.attn.c_attn.v.6': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.7.attn.c_attn.v.7': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.7.attn.c_attn.v.8': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.7.attn.c_attn.v.9': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.7.attn.c_attn.v.10': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.7.attn.c_attn.v.11': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.7.attn.c_proj': ShareLinear(in=768, basis=768, out=768, state=original),\n",
       " 'model.transformer.h.7.mlp.c_fc': ShareLinear(in=768, basis=768, out=3072, state=original),\n",
       " 'model.transformer.h.7.mlp.c_proj': ShareLinear(in=3072, basis=3072, out=768, state=original),\n",
       " 'model.transformer.h.8.attn.c_attn.q.0': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.8.attn.c_attn.q.1': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.8.attn.c_attn.q.2': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.8.attn.c_attn.q.3': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.8.attn.c_attn.q.4': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.8.attn.c_attn.q.5': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.8.attn.c_attn.q.6': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.8.attn.c_attn.q.7': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.8.attn.c_attn.q.8': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.8.attn.c_attn.q.9': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.8.attn.c_attn.q.10': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.8.attn.c_attn.q.11': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.8.attn.c_attn.k.0': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.8.attn.c_attn.k.1': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.8.attn.c_attn.k.2': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.8.attn.c_attn.k.3': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.8.attn.c_attn.k.4': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.8.attn.c_attn.k.5': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.8.attn.c_attn.k.6': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.8.attn.c_attn.k.7': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.8.attn.c_attn.k.8': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.8.attn.c_attn.k.9': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.8.attn.c_attn.k.10': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.8.attn.c_attn.k.11': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.8.attn.c_attn.v.0': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.8.attn.c_attn.v.1': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.8.attn.c_attn.v.2': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.8.attn.c_attn.v.3': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.8.attn.c_attn.v.4': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.8.attn.c_attn.v.5': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.8.attn.c_attn.v.6': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.8.attn.c_attn.v.7': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.8.attn.c_attn.v.8': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.8.attn.c_attn.v.9': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.8.attn.c_attn.v.10': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.8.attn.c_attn.v.11': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.8.attn.c_proj': ShareLinear(in=768, basis=768, out=768, state=original),\n",
       " 'model.transformer.h.8.mlp.c_fc': ShareLinear(in=768, basis=768, out=3072, state=original),\n",
       " 'model.transformer.h.8.mlp.c_proj': ShareLinear(in=3072, basis=3072, out=768, state=original),\n",
       " 'model.transformer.h.9.attn.c_attn.q.0': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.9.attn.c_attn.q.1': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.9.attn.c_attn.q.2': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.9.attn.c_attn.q.3': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.9.attn.c_attn.q.4': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.9.attn.c_attn.q.5': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.9.attn.c_attn.q.6': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.9.attn.c_attn.q.7': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.9.attn.c_attn.q.8': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.9.attn.c_attn.q.9': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.9.attn.c_attn.q.10': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.9.attn.c_attn.q.11': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.9.attn.c_attn.k.0': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.9.attn.c_attn.k.1': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.9.attn.c_attn.k.2': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.9.attn.c_attn.k.3': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.9.attn.c_attn.k.4': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.9.attn.c_attn.k.5': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.9.attn.c_attn.k.6': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.9.attn.c_attn.k.7': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.9.attn.c_attn.k.8': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.9.attn.c_attn.k.9': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.9.attn.c_attn.k.10': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.9.attn.c_attn.k.11': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.9.attn.c_attn.v.0': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.9.attn.c_attn.v.1': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.9.attn.c_attn.v.2': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.9.attn.c_attn.v.3': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.9.attn.c_attn.v.4': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.9.attn.c_attn.v.5': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.9.attn.c_attn.v.6': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.9.attn.c_attn.v.7': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.9.attn.c_attn.v.8': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.9.attn.c_attn.v.9': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.9.attn.c_attn.v.10': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.9.attn.c_attn.v.11': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.9.attn.c_proj': ShareLinear(in=768, basis=768, out=768, state=original),\n",
       " 'model.transformer.h.9.mlp.c_fc': ShareLinear(in=768, basis=768, out=3072, state=original),\n",
       " 'model.transformer.h.9.mlp.c_proj': ShareLinear(in=3072, basis=3072, out=768, state=original),\n",
       " 'model.transformer.h.10.attn.c_attn.q.0': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.10.attn.c_attn.q.1': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.10.attn.c_attn.q.2': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.10.attn.c_attn.q.3': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.10.attn.c_attn.q.4': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.10.attn.c_attn.q.5': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.10.attn.c_attn.q.6': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.10.attn.c_attn.q.7': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.10.attn.c_attn.q.8': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.10.attn.c_attn.q.9': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.10.attn.c_attn.q.10': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.10.attn.c_attn.q.11': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.10.attn.c_attn.k.0': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.10.attn.c_attn.k.1': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.10.attn.c_attn.k.2': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.10.attn.c_attn.k.3': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.10.attn.c_attn.k.4': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.10.attn.c_attn.k.5': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.10.attn.c_attn.k.6': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.10.attn.c_attn.k.7': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.10.attn.c_attn.k.8': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.10.attn.c_attn.k.9': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.10.attn.c_attn.k.10': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.10.attn.c_attn.k.11': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.10.attn.c_attn.v.0': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.10.attn.c_attn.v.1': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.10.attn.c_attn.v.2': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.10.attn.c_attn.v.3': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.10.attn.c_attn.v.4': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.10.attn.c_attn.v.5': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.10.attn.c_attn.v.6': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.10.attn.c_attn.v.7': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.10.attn.c_attn.v.8': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.10.attn.c_attn.v.9': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.10.attn.c_attn.v.10': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.10.attn.c_attn.v.11': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.10.attn.c_proj': ShareLinear(in=768, basis=768, out=768, state=original),\n",
       " 'model.transformer.h.10.mlp.c_fc': ShareLinear(in=768, basis=768, out=3072, state=original),\n",
       " 'model.transformer.h.10.mlp.c_proj': ShareLinear(in=3072, basis=3072, out=768, state=original),\n",
       " 'model.transformer.h.11.attn.c_attn.q.0': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.11.attn.c_attn.q.1': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.11.attn.c_attn.q.2': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.11.attn.c_attn.q.3': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.11.attn.c_attn.q.4': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.11.attn.c_attn.q.5': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.11.attn.c_attn.q.6': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.11.attn.c_attn.q.7': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.11.attn.c_attn.q.8': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.11.attn.c_attn.q.9': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.11.attn.c_attn.q.10': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.11.attn.c_attn.q.11': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.11.attn.c_attn.k.0': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.11.attn.c_attn.k.1': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.11.attn.c_attn.k.2': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.11.attn.c_attn.k.3': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.11.attn.c_attn.k.4': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.11.attn.c_attn.k.5': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.11.attn.c_attn.k.6': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.11.attn.c_attn.k.7': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.11.attn.c_attn.k.8': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.11.attn.c_attn.k.9': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.11.attn.c_attn.k.10': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.11.attn.c_attn.k.11': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.11.attn.c_attn.v.0': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.11.attn.c_attn.v.1': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.11.attn.c_attn.v.2': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.11.attn.c_attn.v.3': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.11.attn.c_attn.v.4': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.11.attn.c_attn.v.5': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.11.attn.c_attn.v.6': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.11.attn.c_attn.v.7': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.11.attn.c_attn.v.8': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.11.attn.c_attn.v.9': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.11.attn.c_attn.v.10': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.11.attn.c_attn.v.11': ShareLinear(in=768, basis=768, out=64, state=original),\n",
       " 'model.transformer.h.11.attn.c_proj': ShareLinear(in=768, basis=768, out=768, state=original),\n",
       " 'model.transformer.h.11.mlp.c_fc': ShareLinear(in=768, basis=768, out=3072, state=original),\n",
       " 'model.transformer.h.11.mlp.c_proj': ShareLinear(in=3072, basis=3072, out=768, state=original)}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrapper.all_basislinears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd89f808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list, {})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrapper.weight_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd779363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('',\n",
       "  GPT2Foundation(\n",
       "    (model): GPT(\n",
       "      (transformer): ModuleDict(\n",
       "        (wte): Embedding(50257, 768)\n",
       "        (wpe): Embedding(1024, 768)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "        (h): ModuleList(\n",
       "          (0-11): 12 x Block(\n",
       "            (ln_1): LayerNorm()\n",
       "            (attn): CausalSelfAttention(\n",
       "              (c_attn): SplitLinear(\n",
       "                (splits): ModuleList(\n",
       "                  (0-35): 36 x ShareLinear(in=768, basis=768, out=64, state=original)\n",
       "                )\n",
       "              )\n",
       "              (c_proj): SplitLinear(\n",
       "                (splits): ModuleList(\n",
       "                  (0): ShareLinear(in=768, basis=768, out=768, state=original)\n",
       "                )\n",
       "              )\n",
       "              (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ln_2): LayerNorm()\n",
       "            (mlp): MLP(\n",
       "              (c_fc): SplitLinear(\n",
       "                (splits): ModuleList(\n",
       "                  (0): ShareLinear(in=768, basis=768, out=3072, state=original)\n",
       "                )\n",
       "              )\n",
       "              (gelu): GELU(approximate='none')\n",
       "              (c_proj): SplitLinear(\n",
       "                (splits): ModuleList(\n",
       "                  (0): ShareLinear(in=3072, basis=3072, out=768, state=original)\n",
       "                )\n",
       "              )\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (ln_f): LayerNorm()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       "    )\n",
       "  )),\n",
       " ('model',\n",
       "  GPT(\n",
       "    (transformer): ModuleDict(\n",
       "      (wte): Embedding(50257, 768)\n",
       "      (wpe): Embedding(1024, 768)\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "      (h): ModuleList(\n",
       "        (0-11): 12 x Block(\n",
       "          (ln_1): LayerNorm()\n",
       "          (attn): CausalSelfAttention(\n",
       "            (c_attn): SplitLinear(\n",
       "              (splits): ModuleList(\n",
       "                (0-35): 36 x ShareLinear(in=768, basis=768, out=64, state=original)\n",
       "              )\n",
       "            )\n",
       "            (c_proj): SplitLinear(\n",
       "              (splits): ModuleList(\n",
       "                (0): ShareLinear(in=768, basis=768, out=768, state=original)\n",
       "              )\n",
       "            )\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm()\n",
       "          (mlp): MLP(\n",
       "            (c_fc): SplitLinear(\n",
       "              (splits): ModuleList(\n",
       "                (0): ShareLinear(in=768, basis=768, out=3072, state=original)\n",
       "              )\n",
       "            )\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): SplitLinear(\n",
       "              (splits): ModuleList(\n",
       "                (0): ShareLinear(in=3072, basis=3072, out=768, state=original)\n",
       "              )\n",
       "            )\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_f): LayerNorm()\n",
       "    )\n",
       "    (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       "  )),\n",
       " ('model.transformer',\n",
       "  ModuleDict(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x Block(\n",
       "        (ln_1): LayerNorm()\n",
       "        (attn): CausalSelfAttention(\n",
       "          (c_attn): SplitLinear(\n",
       "            (splits): ModuleList(\n",
       "              (0-35): 36 x ShareLinear(in=768, basis=768, out=64, state=original)\n",
       "            )\n",
       "          )\n",
       "          (c_proj): SplitLinear(\n",
       "            (splits): ModuleList(\n",
       "              (0): ShareLinear(in=768, basis=768, out=768, state=original)\n",
       "            )\n",
       "          )\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm()\n",
       "        (mlp): MLP(\n",
       "          (c_fc): SplitLinear(\n",
       "            (splits): ModuleList(\n",
       "              (0): ShareLinear(in=768, basis=768, out=3072, state=original)\n",
       "            )\n",
       "          )\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (c_proj): SplitLinear(\n",
       "            (splits): ModuleList(\n",
       "              (0): ShareLinear(in=3072, basis=3072, out=768, state=original)\n",
       "            )\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm()\n",
       "  )),\n",
       " ('model.transformer.wte', Embedding(50257, 768)),\n",
       " ('model.transformer.wpe', Embedding(1024, 768)),\n",
       " ('model.transformer.drop', Dropout(p=0.0, inplace=False)),\n",
       " ('model.transformer.h',\n",
       "  ModuleList(\n",
       "    (0-11): 12 x Block(\n",
       "      (ln_1): LayerNorm()\n",
       "      (attn): CausalSelfAttention(\n",
       "        (c_attn): SplitLinear(\n",
       "          (splits): ModuleList(\n",
       "            (0-35): 36 x ShareLinear(in=768, basis=768, out=64, state=original)\n",
       "          )\n",
       "        )\n",
       "        (c_proj): SplitLinear(\n",
       "          (splits): ModuleList(\n",
       "            (0): ShareLinear(in=768, basis=768, out=768, state=original)\n",
       "          )\n",
       "        )\n",
       "        (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm()\n",
       "      (mlp): MLP(\n",
       "        (c_fc): SplitLinear(\n",
       "          (splits): ModuleList(\n",
       "            (0): ShareLinear(in=768, basis=768, out=3072, state=original)\n",
       "          )\n",
       "        )\n",
       "        (gelu): GELU(approximate='none')\n",
       "        (c_proj): SplitLinear(\n",
       "          (splits): ModuleList(\n",
       "            (0): ShareLinear(in=3072, basis=3072, out=768, state=original)\n",
       "          )\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )),\n",
       " ('model.transformer.h.0',\n",
       "  Block(\n",
       "    (ln_1): LayerNorm()\n",
       "    (attn): CausalSelfAttention(\n",
       "      (c_attn): SplitLinear(\n",
       "        (splits): ModuleList(\n",
       "          (0-35): 36 x ShareLinear(in=768, basis=768, out=64, state=original)\n",
       "        )\n",
       "      )\n",
       "      (c_proj): SplitLinear(\n",
       "        (splits): ModuleList(\n",
       "          (0): ShareLinear(in=768, basis=768, out=768, state=original)\n",
       "        )\n",
       "      )\n",
       "      (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "      (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (ln_2): LayerNorm()\n",
       "    (mlp): MLP(\n",
       "      (c_fc): SplitLinear(\n",
       "        (splits): ModuleList(\n",
       "          (0): ShareLinear(in=768, basis=768, out=3072, state=original)\n",
       "        )\n",
       "      )\n",
       "      (gelu): GELU(approximate='none')\n",
       "      (c_proj): SplitLinear(\n",
       "        (splits): ModuleList(\n",
       "          (0): ShareLinear(in=3072, basis=3072, out=768, state=original)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )),\n",
       " ('model.transformer.h.0.ln_1', LayerNorm()),\n",
       " ('model.transformer.h.0.attn',\n",
       "  CausalSelfAttention(\n",
       "    (c_attn): SplitLinear(\n",
       "      (splits): ModuleList(\n",
       "        (0-35): 36 x ShareLinear(in=768, basis=768, out=64, state=original)\n",
       "      )\n",
       "    )\n",
       "    (c_proj): SplitLinear(\n",
       "      (splits): ModuleList(\n",
       "        (0): ShareLinear(in=768, basis=768, out=768, state=original)\n",
       "      )\n",
       "    )\n",
       "    (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "  )),\n",
       " ('model.transformer.h.0.attn.c_attn',\n",
       "  SplitLinear(\n",
       "    (splits): ModuleList(\n",
       "      (0-35): 36 x ShareLinear(in=768, basis=768, out=64, state=original)\n",
       "    )\n",
       "  )),\n",
       " ('model.transformer.h.0.attn.c_attn.splits',\n",
       "  ModuleList(\n",
       "    (0-35): 36 x ShareLinear(in=768, basis=768, out=64, state=original)\n",
       "  )),\n",
       " ('model.transformer.h.0.attn.c_attn.splits.0',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.0.attn.c_attn.splits.1',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.0.attn.c_attn.splits.2',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.0.attn.c_attn.splits.3',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.0.attn.c_attn.splits.4',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.0.attn.c_attn.splits.5',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.0.attn.c_attn.splits.6',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.0.attn.c_attn.splits.7',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.0.attn.c_attn.splits.8',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.0.attn.c_attn.splits.9',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.0.attn.c_attn.splits.10',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.0.attn.c_attn.splits.11',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.0.attn.c_attn.splits.12',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.0.attn.c_attn.splits.13',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.0.attn.c_attn.splits.14',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.0.attn.c_attn.splits.15',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.0.attn.c_attn.splits.16',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.0.attn.c_attn.splits.17',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.0.attn.c_attn.splits.18',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.0.attn.c_attn.splits.19',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.0.attn.c_attn.splits.20',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.0.attn.c_attn.splits.21',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.0.attn.c_attn.splits.22',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.0.attn.c_attn.splits.23',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.0.attn.c_attn.splits.24',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.0.attn.c_attn.splits.25',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.0.attn.c_attn.splits.26',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.0.attn.c_attn.splits.27',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.0.attn.c_attn.splits.28',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.0.attn.c_attn.splits.29',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.0.attn.c_attn.splits.30',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.0.attn.c_attn.splits.31',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.0.attn.c_attn.splits.32',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.0.attn.c_attn.splits.33',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.0.attn.c_attn.splits.34',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.0.attn.c_attn.splits.35',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.0.attn.c_proj',\n",
       "  SplitLinear(\n",
       "    (splits): ModuleList(\n",
       "      (0): ShareLinear(in=768, basis=768, out=768, state=original)\n",
       "    )\n",
       "  )),\n",
       " ('model.transformer.h.0.attn.c_proj.splits',\n",
       "  ModuleList(\n",
       "    (0): ShareLinear(in=768, basis=768, out=768, state=original)\n",
       "  )),\n",
       " ('model.transformer.h.0.attn.c_proj.splits.0',\n",
       "  ShareLinear(in=768, basis=768, out=768, state=original)),\n",
       " ('model.transformer.h.0.attn.attn_dropout', Dropout(p=0.0, inplace=False)),\n",
       " ('model.transformer.h.0.attn.resid_dropout', Dropout(p=0.0, inplace=False)),\n",
       " ('model.transformer.h.0.ln_2', LayerNorm()),\n",
       " ('model.transformer.h.0.mlp',\n",
       "  MLP(\n",
       "    (c_fc): SplitLinear(\n",
       "      (splits): ModuleList(\n",
       "        (0): ShareLinear(in=768, basis=768, out=3072, state=original)\n",
       "      )\n",
       "    )\n",
       "    (gelu): GELU(approximate='none')\n",
       "    (c_proj): SplitLinear(\n",
       "      (splits): ModuleList(\n",
       "        (0): ShareLinear(in=3072, basis=3072, out=768, state=original)\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )),\n",
       " ('model.transformer.h.0.mlp.c_fc',\n",
       "  SplitLinear(\n",
       "    (splits): ModuleList(\n",
       "      (0): ShareLinear(in=768, basis=768, out=3072, state=original)\n",
       "    )\n",
       "  )),\n",
       " ('model.transformer.h.0.mlp.c_fc.splits',\n",
       "  ModuleList(\n",
       "    (0): ShareLinear(in=768, basis=768, out=3072, state=original)\n",
       "  )),\n",
       " ('model.transformer.h.0.mlp.c_fc.splits.0',\n",
       "  ShareLinear(in=768, basis=768, out=3072, state=original)),\n",
       " ('model.transformer.h.0.mlp.gelu', GELU(approximate='none')),\n",
       " ('model.transformer.h.0.mlp.c_proj',\n",
       "  SplitLinear(\n",
       "    (splits): ModuleList(\n",
       "      (0): ShareLinear(in=3072, basis=3072, out=768, state=original)\n",
       "    )\n",
       "  )),\n",
       " ('model.transformer.h.0.mlp.c_proj.splits',\n",
       "  ModuleList(\n",
       "    (0): ShareLinear(in=3072, basis=3072, out=768, state=original)\n",
       "  )),\n",
       " ('model.transformer.h.0.mlp.c_proj.splits.0',\n",
       "  ShareLinear(in=3072, basis=3072, out=768, state=original)),\n",
       " ('model.transformer.h.0.mlp.dropout', Dropout(p=0.0, inplace=False)),\n",
       " ('model.transformer.h.1',\n",
       "  Block(\n",
       "    (ln_1): LayerNorm()\n",
       "    (attn): CausalSelfAttention(\n",
       "      (c_attn): SplitLinear(\n",
       "        (splits): ModuleList(\n",
       "          (0-35): 36 x ShareLinear(in=768, basis=768, out=64, state=original)\n",
       "        )\n",
       "      )\n",
       "      (c_proj): SplitLinear(\n",
       "        (splits): ModuleList(\n",
       "          (0): ShareLinear(in=768, basis=768, out=768, state=original)\n",
       "        )\n",
       "      )\n",
       "      (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "      (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (ln_2): LayerNorm()\n",
       "    (mlp): MLP(\n",
       "      (c_fc): SplitLinear(\n",
       "        (splits): ModuleList(\n",
       "          (0): ShareLinear(in=768, basis=768, out=3072, state=original)\n",
       "        )\n",
       "      )\n",
       "      (gelu): GELU(approximate='none')\n",
       "      (c_proj): SplitLinear(\n",
       "        (splits): ModuleList(\n",
       "          (0): ShareLinear(in=3072, basis=3072, out=768, state=original)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )),\n",
       " ('model.transformer.h.1.ln_1', LayerNorm()),\n",
       " ('model.transformer.h.1.attn',\n",
       "  CausalSelfAttention(\n",
       "    (c_attn): SplitLinear(\n",
       "      (splits): ModuleList(\n",
       "        (0-35): 36 x ShareLinear(in=768, basis=768, out=64, state=original)\n",
       "      )\n",
       "    )\n",
       "    (c_proj): SplitLinear(\n",
       "      (splits): ModuleList(\n",
       "        (0): ShareLinear(in=768, basis=768, out=768, state=original)\n",
       "      )\n",
       "    )\n",
       "    (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "  )),\n",
       " ('model.transformer.h.1.attn.c_attn',\n",
       "  SplitLinear(\n",
       "    (splits): ModuleList(\n",
       "      (0-35): 36 x ShareLinear(in=768, basis=768, out=64, state=original)\n",
       "    )\n",
       "  )),\n",
       " ('model.transformer.h.1.attn.c_attn.splits',\n",
       "  ModuleList(\n",
       "    (0-35): 36 x ShareLinear(in=768, basis=768, out=64, state=original)\n",
       "  )),\n",
       " ('model.transformer.h.1.attn.c_attn.splits.0',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.1.attn.c_attn.splits.1',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.1.attn.c_attn.splits.2',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.1.attn.c_attn.splits.3',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.1.attn.c_attn.splits.4',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.1.attn.c_attn.splits.5',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.1.attn.c_attn.splits.6',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.1.attn.c_attn.splits.7',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.1.attn.c_attn.splits.8',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.1.attn.c_attn.splits.9',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.1.attn.c_attn.splits.10',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.1.attn.c_attn.splits.11',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.1.attn.c_attn.splits.12',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.1.attn.c_attn.splits.13',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.1.attn.c_attn.splits.14',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.1.attn.c_attn.splits.15',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.1.attn.c_attn.splits.16',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.1.attn.c_attn.splits.17',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.1.attn.c_attn.splits.18',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.1.attn.c_attn.splits.19',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.1.attn.c_attn.splits.20',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.1.attn.c_attn.splits.21',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.1.attn.c_attn.splits.22',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.1.attn.c_attn.splits.23',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.1.attn.c_attn.splits.24',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.1.attn.c_attn.splits.25',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.1.attn.c_attn.splits.26',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.1.attn.c_attn.splits.27',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.1.attn.c_attn.splits.28',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.1.attn.c_attn.splits.29',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.1.attn.c_attn.splits.30',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.1.attn.c_attn.splits.31',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.1.attn.c_attn.splits.32',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.1.attn.c_attn.splits.33',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.1.attn.c_attn.splits.34',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.1.attn.c_attn.splits.35',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.1.attn.c_proj',\n",
       "  SplitLinear(\n",
       "    (splits): ModuleList(\n",
       "      (0): ShareLinear(in=768, basis=768, out=768, state=original)\n",
       "    )\n",
       "  )),\n",
       " ('model.transformer.h.1.attn.c_proj.splits',\n",
       "  ModuleList(\n",
       "    (0): ShareLinear(in=768, basis=768, out=768, state=original)\n",
       "  )),\n",
       " ('model.transformer.h.1.attn.c_proj.splits.0',\n",
       "  ShareLinear(in=768, basis=768, out=768, state=original)),\n",
       " ('model.transformer.h.1.attn.attn_dropout', Dropout(p=0.0, inplace=False)),\n",
       " ('model.transformer.h.1.attn.resid_dropout', Dropout(p=0.0, inplace=False)),\n",
       " ('model.transformer.h.1.ln_2', LayerNorm()),\n",
       " ('model.transformer.h.1.mlp',\n",
       "  MLP(\n",
       "    (c_fc): SplitLinear(\n",
       "      (splits): ModuleList(\n",
       "        (0): ShareLinear(in=768, basis=768, out=3072, state=original)\n",
       "      )\n",
       "    )\n",
       "    (gelu): GELU(approximate='none')\n",
       "    (c_proj): SplitLinear(\n",
       "      (splits): ModuleList(\n",
       "        (0): ShareLinear(in=3072, basis=3072, out=768, state=original)\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )),\n",
       " ('model.transformer.h.1.mlp.c_fc',\n",
       "  SplitLinear(\n",
       "    (splits): ModuleList(\n",
       "      (0): ShareLinear(in=768, basis=768, out=3072, state=original)\n",
       "    )\n",
       "  )),\n",
       " ('model.transformer.h.1.mlp.c_fc.splits',\n",
       "  ModuleList(\n",
       "    (0): ShareLinear(in=768, basis=768, out=3072, state=original)\n",
       "  )),\n",
       " ('model.transformer.h.1.mlp.c_fc.splits.0',\n",
       "  ShareLinear(in=768, basis=768, out=3072, state=original)),\n",
       " ('model.transformer.h.1.mlp.gelu', GELU(approximate='none')),\n",
       " ('model.transformer.h.1.mlp.c_proj',\n",
       "  SplitLinear(\n",
       "    (splits): ModuleList(\n",
       "      (0): ShareLinear(in=3072, basis=3072, out=768, state=original)\n",
       "    )\n",
       "  )),\n",
       " ('model.transformer.h.1.mlp.c_proj.splits',\n",
       "  ModuleList(\n",
       "    (0): ShareLinear(in=3072, basis=3072, out=768, state=original)\n",
       "  )),\n",
       " ('model.transformer.h.1.mlp.c_proj.splits.0',\n",
       "  ShareLinear(in=3072, basis=3072, out=768, state=original)),\n",
       " ('model.transformer.h.1.mlp.dropout', Dropout(p=0.0, inplace=False)),\n",
       " ('model.transformer.h.2',\n",
       "  Block(\n",
       "    (ln_1): LayerNorm()\n",
       "    (attn): CausalSelfAttention(\n",
       "      (c_attn): SplitLinear(\n",
       "        (splits): ModuleList(\n",
       "          (0-35): 36 x ShareLinear(in=768, basis=768, out=64, state=original)\n",
       "        )\n",
       "      )\n",
       "      (c_proj): SplitLinear(\n",
       "        (splits): ModuleList(\n",
       "          (0): ShareLinear(in=768, basis=768, out=768, state=original)\n",
       "        )\n",
       "      )\n",
       "      (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "      (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (ln_2): LayerNorm()\n",
       "    (mlp): MLP(\n",
       "      (c_fc): SplitLinear(\n",
       "        (splits): ModuleList(\n",
       "          (0): ShareLinear(in=768, basis=768, out=3072, state=original)\n",
       "        )\n",
       "      )\n",
       "      (gelu): GELU(approximate='none')\n",
       "      (c_proj): SplitLinear(\n",
       "        (splits): ModuleList(\n",
       "          (0): ShareLinear(in=3072, basis=3072, out=768, state=original)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )),\n",
       " ('model.transformer.h.2.ln_1', LayerNorm()),\n",
       " ('model.transformer.h.2.attn',\n",
       "  CausalSelfAttention(\n",
       "    (c_attn): SplitLinear(\n",
       "      (splits): ModuleList(\n",
       "        (0-35): 36 x ShareLinear(in=768, basis=768, out=64, state=original)\n",
       "      )\n",
       "    )\n",
       "    (c_proj): SplitLinear(\n",
       "      (splits): ModuleList(\n",
       "        (0): ShareLinear(in=768, basis=768, out=768, state=original)\n",
       "      )\n",
       "    )\n",
       "    (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "  )),\n",
       " ('model.transformer.h.2.attn.c_attn',\n",
       "  SplitLinear(\n",
       "    (splits): ModuleList(\n",
       "      (0-35): 36 x ShareLinear(in=768, basis=768, out=64, state=original)\n",
       "    )\n",
       "  )),\n",
       " ('model.transformer.h.2.attn.c_attn.splits',\n",
       "  ModuleList(\n",
       "    (0-35): 36 x ShareLinear(in=768, basis=768, out=64, state=original)\n",
       "  )),\n",
       " ('model.transformer.h.2.attn.c_attn.splits.0',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.2.attn.c_attn.splits.1',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.2.attn.c_attn.splits.2',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.2.attn.c_attn.splits.3',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.2.attn.c_attn.splits.4',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.2.attn.c_attn.splits.5',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.2.attn.c_attn.splits.6',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.2.attn.c_attn.splits.7',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.2.attn.c_attn.splits.8',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.2.attn.c_attn.splits.9',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.2.attn.c_attn.splits.10',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.2.attn.c_attn.splits.11',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.2.attn.c_attn.splits.12',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.2.attn.c_attn.splits.13',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.2.attn.c_attn.splits.14',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.2.attn.c_attn.splits.15',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.2.attn.c_attn.splits.16',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.2.attn.c_attn.splits.17',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.2.attn.c_attn.splits.18',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.2.attn.c_attn.splits.19',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.2.attn.c_attn.splits.20',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.2.attn.c_attn.splits.21',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.2.attn.c_attn.splits.22',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.2.attn.c_attn.splits.23',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.2.attn.c_attn.splits.24',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.2.attn.c_attn.splits.25',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.2.attn.c_attn.splits.26',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.2.attn.c_attn.splits.27',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.2.attn.c_attn.splits.28',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.2.attn.c_attn.splits.29',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.2.attn.c_attn.splits.30',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.2.attn.c_attn.splits.31',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.2.attn.c_attn.splits.32',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.2.attn.c_attn.splits.33',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.2.attn.c_attn.splits.34',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.2.attn.c_attn.splits.35',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.2.attn.c_proj',\n",
       "  SplitLinear(\n",
       "    (splits): ModuleList(\n",
       "      (0): ShareLinear(in=768, basis=768, out=768, state=original)\n",
       "    )\n",
       "  )),\n",
       " ('model.transformer.h.2.attn.c_proj.splits',\n",
       "  ModuleList(\n",
       "    (0): ShareLinear(in=768, basis=768, out=768, state=original)\n",
       "  )),\n",
       " ('model.transformer.h.2.attn.c_proj.splits.0',\n",
       "  ShareLinear(in=768, basis=768, out=768, state=original)),\n",
       " ('model.transformer.h.2.attn.attn_dropout', Dropout(p=0.0, inplace=False)),\n",
       " ('model.transformer.h.2.attn.resid_dropout', Dropout(p=0.0, inplace=False)),\n",
       " ('model.transformer.h.2.ln_2', LayerNorm()),\n",
       " ('model.transformer.h.2.mlp',\n",
       "  MLP(\n",
       "    (c_fc): SplitLinear(\n",
       "      (splits): ModuleList(\n",
       "        (0): ShareLinear(in=768, basis=768, out=3072, state=original)\n",
       "      )\n",
       "    )\n",
       "    (gelu): GELU(approximate='none')\n",
       "    (c_proj): SplitLinear(\n",
       "      (splits): ModuleList(\n",
       "        (0): ShareLinear(in=3072, basis=3072, out=768, state=original)\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )),\n",
       " ('model.transformer.h.2.mlp.c_fc',\n",
       "  SplitLinear(\n",
       "    (splits): ModuleList(\n",
       "      (0): ShareLinear(in=768, basis=768, out=3072, state=original)\n",
       "    )\n",
       "  )),\n",
       " ('model.transformer.h.2.mlp.c_fc.splits',\n",
       "  ModuleList(\n",
       "    (0): ShareLinear(in=768, basis=768, out=3072, state=original)\n",
       "  )),\n",
       " ('model.transformer.h.2.mlp.c_fc.splits.0',\n",
       "  ShareLinear(in=768, basis=768, out=3072, state=original)),\n",
       " ('model.transformer.h.2.mlp.gelu', GELU(approximate='none')),\n",
       " ('model.transformer.h.2.mlp.c_proj',\n",
       "  SplitLinear(\n",
       "    (splits): ModuleList(\n",
       "      (0): ShareLinear(in=3072, basis=3072, out=768, state=original)\n",
       "    )\n",
       "  )),\n",
       " ('model.transformer.h.2.mlp.c_proj.splits',\n",
       "  ModuleList(\n",
       "    (0): ShareLinear(in=3072, basis=3072, out=768, state=original)\n",
       "  )),\n",
       " ('model.transformer.h.2.mlp.c_proj.splits.0',\n",
       "  ShareLinear(in=3072, basis=3072, out=768, state=original)),\n",
       " ('model.transformer.h.2.mlp.dropout', Dropout(p=0.0, inplace=False)),\n",
       " ('model.transformer.h.3',\n",
       "  Block(\n",
       "    (ln_1): LayerNorm()\n",
       "    (attn): CausalSelfAttention(\n",
       "      (c_attn): SplitLinear(\n",
       "        (splits): ModuleList(\n",
       "          (0-35): 36 x ShareLinear(in=768, basis=768, out=64, state=original)\n",
       "        )\n",
       "      )\n",
       "      (c_proj): SplitLinear(\n",
       "        (splits): ModuleList(\n",
       "          (0): ShareLinear(in=768, basis=768, out=768, state=original)\n",
       "        )\n",
       "      )\n",
       "      (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "      (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (ln_2): LayerNorm()\n",
       "    (mlp): MLP(\n",
       "      (c_fc): SplitLinear(\n",
       "        (splits): ModuleList(\n",
       "          (0): ShareLinear(in=768, basis=768, out=3072, state=original)\n",
       "        )\n",
       "      )\n",
       "      (gelu): GELU(approximate='none')\n",
       "      (c_proj): SplitLinear(\n",
       "        (splits): ModuleList(\n",
       "          (0): ShareLinear(in=3072, basis=3072, out=768, state=original)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )),\n",
       " ('model.transformer.h.3.ln_1', LayerNorm()),\n",
       " ('model.transformer.h.3.attn',\n",
       "  CausalSelfAttention(\n",
       "    (c_attn): SplitLinear(\n",
       "      (splits): ModuleList(\n",
       "        (0-35): 36 x ShareLinear(in=768, basis=768, out=64, state=original)\n",
       "      )\n",
       "    )\n",
       "    (c_proj): SplitLinear(\n",
       "      (splits): ModuleList(\n",
       "        (0): ShareLinear(in=768, basis=768, out=768, state=original)\n",
       "      )\n",
       "    )\n",
       "    (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "  )),\n",
       " ('model.transformer.h.3.attn.c_attn',\n",
       "  SplitLinear(\n",
       "    (splits): ModuleList(\n",
       "      (0-35): 36 x ShareLinear(in=768, basis=768, out=64, state=original)\n",
       "    )\n",
       "  )),\n",
       " ('model.transformer.h.3.attn.c_attn.splits',\n",
       "  ModuleList(\n",
       "    (0-35): 36 x ShareLinear(in=768, basis=768, out=64, state=original)\n",
       "  )),\n",
       " ('model.transformer.h.3.attn.c_attn.splits.0',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.3.attn.c_attn.splits.1',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.3.attn.c_attn.splits.2',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.3.attn.c_attn.splits.3',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.3.attn.c_attn.splits.4',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.3.attn.c_attn.splits.5',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.3.attn.c_attn.splits.6',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.3.attn.c_attn.splits.7',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.3.attn.c_attn.splits.8',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.3.attn.c_attn.splits.9',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.3.attn.c_attn.splits.10',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.3.attn.c_attn.splits.11',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.3.attn.c_attn.splits.12',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.3.attn.c_attn.splits.13',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.3.attn.c_attn.splits.14',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.3.attn.c_attn.splits.15',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.3.attn.c_attn.splits.16',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.3.attn.c_attn.splits.17',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.3.attn.c_attn.splits.18',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.3.attn.c_attn.splits.19',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.3.attn.c_attn.splits.20',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.3.attn.c_attn.splits.21',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.3.attn.c_attn.splits.22',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.3.attn.c_attn.splits.23',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.3.attn.c_attn.splits.24',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.3.attn.c_attn.splits.25',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.3.attn.c_attn.splits.26',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.3.attn.c_attn.splits.27',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.3.attn.c_attn.splits.28',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.3.attn.c_attn.splits.29',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.3.attn.c_attn.splits.30',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.3.attn.c_attn.splits.31',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.3.attn.c_attn.splits.32',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.3.attn.c_attn.splits.33',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.3.attn.c_attn.splits.34',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.3.attn.c_attn.splits.35',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.3.attn.c_proj',\n",
       "  SplitLinear(\n",
       "    (splits): ModuleList(\n",
       "      (0): ShareLinear(in=768, basis=768, out=768, state=original)\n",
       "    )\n",
       "  )),\n",
       " ('model.transformer.h.3.attn.c_proj.splits',\n",
       "  ModuleList(\n",
       "    (0): ShareLinear(in=768, basis=768, out=768, state=original)\n",
       "  )),\n",
       " ('model.transformer.h.3.attn.c_proj.splits.0',\n",
       "  ShareLinear(in=768, basis=768, out=768, state=original)),\n",
       " ('model.transformer.h.3.attn.attn_dropout', Dropout(p=0.0, inplace=False)),\n",
       " ('model.transformer.h.3.attn.resid_dropout', Dropout(p=0.0, inplace=False)),\n",
       " ('model.transformer.h.3.ln_2', LayerNorm()),\n",
       " ('model.transformer.h.3.mlp',\n",
       "  MLP(\n",
       "    (c_fc): SplitLinear(\n",
       "      (splits): ModuleList(\n",
       "        (0): ShareLinear(in=768, basis=768, out=3072, state=original)\n",
       "      )\n",
       "    )\n",
       "    (gelu): GELU(approximate='none')\n",
       "    (c_proj): SplitLinear(\n",
       "      (splits): ModuleList(\n",
       "        (0): ShareLinear(in=3072, basis=3072, out=768, state=original)\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )),\n",
       " ('model.transformer.h.3.mlp.c_fc',\n",
       "  SplitLinear(\n",
       "    (splits): ModuleList(\n",
       "      (0): ShareLinear(in=768, basis=768, out=3072, state=original)\n",
       "    )\n",
       "  )),\n",
       " ('model.transformer.h.3.mlp.c_fc.splits',\n",
       "  ModuleList(\n",
       "    (0): ShareLinear(in=768, basis=768, out=3072, state=original)\n",
       "  )),\n",
       " ('model.transformer.h.3.mlp.c_fc.splits.0',\n",
       "  ShareLinear(in=768, basis=768, out=3072, state=original)),\n",
       " ('model.transformer.h.3.mlp.gelu', GELU(approximate='none')),\n",
       " ('model.transformer.h.3.mlp.c_proj',\n",
       "  SplitLinear(\n",
       "    (splits): ModuleList(\n",
       "      (0): ShareLinear(in=3072, basis=3072, out=768, state=original)\n",
       "    )\n",
       "  )),\n",
       " ('model.transformer.h.3.mlp.c_proj.splits',\n",
       "  ModuleList(\n",
       "    (0): ShareLinear(in=3072, basis=3072, out=768, state=original)\n",
       "  )),\n",
       " ('model.transformer.h.3.mlp.c_proj.splits.0',\n",
       "  ShareLinear(in=3072, basis=3072, out=768, state=original)),\n",
       " ('model.transformer.h.3.mlp.dropout', Dropout(p=0.0, inplace=False)),\n",
       " ('model.transformer.h.4',\n",
       "  Block(\n",
       "    (ln_1): LayerNorm()\n",
       "    (attn): CausalSelfAttention(\n",
       "      (c_attn): SplitLinear(\n",
       "        (splits): ModuleList(\n",
       "          (0-35): 36 x ShareLinear(in=768, basis=768, out=64, state=original)\n",
       "        )\n",
       "      )\n",
       "      (c_proj): SplitLinear(\n",
       "        (splits): ModuleList(\n",
       "          (0): ShareLinear(in=768, basis=768, out=768, state=original)\n",
       "        )\n",
       "      )\n",
       "      (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "      (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (ln_2): LayerNorm()\n",
       "    (mlp): MLP(\n",
       "      (c_fc): SplitLinear(\n",
       "        (splits): ModuleList(\n",
       "          (0): ShareLinear(in=768, basis=768, out=3072, state=original)\n",
       "        )\n",
       "      )\n",
       "      (gelu): GELU(approximate='none')\n",
       "      (c_proj): SplitLinear(\n",
       "        (splits): ModuleList(\n",
       "          (0): ShareLinear(in=3072, basis=3072, out=768, state=original)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )),\n",
       " ('model.transformer.h.4.ln_1', LayerNorm()),\n",
       " ('model.transformer.h.4.attn',\n",
       "  CausalSelfAttention(\n",
       "    (c_attn): SplitLinear(\n",
       "      (splits): ModuleList(\n",
       "        (0-35): 36 x ShareLinear(in=768, basis=768, out=64, state=original)\n",
       "      )\n",
       "    )\n",
       "    (c_proj): SplitLinear(\n",
       "      (splits): ModuleList(\n",
       "        (0): ShareLinear(in=768, basis=768, out=768, state=original)\n",
       "      )\n",
       "    )\n",
       "    (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "  )),\n",
       " ('model.transformer.h.4.attn.c_attn',\n",
       "  SplitLinear(\n",
       "    (splits): ModuleList(\n",
       "      (0-35): 36 x ShareLinear(in=768, basis=768, out=64, state=original)\n",
       "    )\n",
       "  )),\n",
       " ('model.transformer.h.4.attn.c_attn.splits',\n",
       "  ModuleList(\n",
       "    (0-35): 36 x ShareLinear(in=768, basis=768, out=64, state=original)\n",
       "  )),\n",
       " ('model.transformer.h.4.attn.c_attn.splits.0',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.4.attn.c_attn.splits.1',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.4.attn.c_attn.splits.2',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.4.attn.c_attn.splits.3',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.4.attn.c_attn.splits.4',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.4.attn.c_attn.splits.5',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.4.attn.c_attn.splits.6',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.4.attn.c_attn.splits.7',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.4.attn.c_attn.splits.8',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.4.attn.c_attn.splits.9',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.4.attn.c_attn.splits.10',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.4.attn.c_attn.splits.11',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.4.attn.c_attn.splits.12',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.4.attn.c_attn.splits.13',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.4.attn.c_attn.splits.14',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.4.attn.c_attn.splits.15',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.4.attn.c_attn.splits.16',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.4.attn.c_attn.splits.17',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.4.attn.c_attn.splits.18',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.4.attn.c_attn.splits.19',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.4.attn.c_attn.splits.20',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.4.attn.c_attn.splits.21',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.4.attn.c_attn.splits.22',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.4.attn.c_attn.splits.23',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.4.attn.c_attn.splits.24',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.4.attn.c_attn.splits.25',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.4.attn.c_attn.splits.26',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.4.attn.c_attn.splits.27',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.4.attn.c_attn.splits.28',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.4.attn.c_attn.splits.29',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.4.attn.c_attn.splits.30',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.4.attn.c_attn.splits.31',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.4.attn.c_attn.splits.32',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.4.attn.c_attn.splits.33',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.4.attn.c_attn.splits.34',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.4.attn.c_attn.splits.35',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.4.attn.c_proj',\n",
       "  SplitLinear(\n",
       "    (splits): ModuleList(\n",
       "      (0): ShareLinear(in=768, basis=768, out=768, state=original)\n",
       "    )\n",
       "  )),\n",
       " ('model.transformer.h.4.attn.c_proj.splits',\n",
       "  ModuleList(\n",
       "    (0): ShareLinear(in=768, basis=768, out=768, state=original)\n",
       "  )),\n",
       " ('model.transformer.h.4.attn.c_proj.splits.0',\n",
       "  ShareLinear(in=768, basis=768, out=768, state=original)),\n",
       " ('model.transformer.h.4.attn.attn_dropout', Dropout(p=0.0, inplace=False)),\n",
       " ('model.transformer.h.4.attn.resid_dropout', Dropout(p=0.0, inplace=False)),\n",
       " ('model.transformer.h.4.ln_2', LayerNorm()),\n",
       " ('model.transformer.h.4.mlp',\n",
       "  MLP(\n",
       "    (c_fc): SplitLinear(\n",
       "      (splits): ModuleList(\n",
       "        (0): ShareLinear(in=768, basis=768, out=3072, state=original)\n",
       "      )\n",
       "    )\n",
       "    (gelu): GELU(approximate='none')\n",
       "    (c_proj): SplitLinear(\n",
       "      (splits): ModuleList(\n",
       "        (0): ShareLinear(in=3072, basis=3072, out=768, state=original)\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )),\n",
       " ('model.transformer.h.4.mlp.c_fc',\n",
       "  SplitLinear(\n",
       "    (splits): ModuleList(\n",
       "      (0): ShareLinear(in=768, basis=768, out=3072, state=original)\n",
       "    )\n",
       "  )),\n",
       " ('model.transformer.h.4.mlp.c_fc.splits',\n",
       "  ModuleList(\n",
       "    (0): ShareLinear(in=768, basis=768, out=3072, state=original)\n",
       "  )),\n",
       " ('model.transformer.h.4.mlp.c_fc.splits.0',\n",
       "  ShareLinear(in=768, basis=768, out=3072, state=original)),\n",
       " ('model.transformer.h.4.mlp.gelu', GELU(approximate='none')),\n",
       " ('model.transformer.h.4.mlp.c_proj',\n",
       "  SplitLinear(\n",
       "    (splits): ModuleList(\n",
       "      (0): ShareLinear(in=3072, basis=3072, out=768, state=original)\n",
       "    )\n",
       "  )),\n",
       " ('model.transformer.h.4.mlp.c_proj.splits',\n",
       "  ModuleList(\n",
       "    (0): ShareLinear(in=3072, basis=3072, out=768, state=original)\n",
       "  )),\n",
       " ('model.transformer.h.4.mlp.c_proj.splits.0',\n",
       "  ShareLinear(in=3072, basis=3072, out=768, state=original)),\n",
       " ('model.transformer.h.4.mlp.dropout', Dropout(p=0.0, inplace=False)),\n",
       " ('model.transformer.h.5',\n",
       "  Block(\n",
       "    (ln_1): LayerNorm()\n",
       "    (attn): CausalSelfAttention(\n",
       "      (c_attn): SplitLinear(\n",
       "        (splits): ModuleList(\n",
       "          (0-35): 36 x ShareLinear(in=768, basis=768, out=64, state=original)\n",
       "        )\n",
       "      )\n",
       "      (c_proj): SplitLinear(\n",
       "        (splits): ModuleList(\n",
       "          (0): ShareLinear(in=768, basis=768, out=768, state=original)\n",
       "        )\n",
       "      )\n",
       "      (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "      (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (ln_2): LayerNorm()\n",
       "    (mlp): MLP(\n",
       "      (c_fc): SplitLinear(\n",
       "        (splits): ModuleList(\n",
       "          (0): ShareLinear(in=768, basis=768, out=3072, state=original)\n",
       "        )\n",
       "      )\n",
       "      (gelu): GELU(approximate='none')\n",
       "      (c_proj): SplitLinear(\n",
       "        (splits): ModuleList(\n",
       "          (0): ShareLinear(in=3072, basis=3072, out=768, state=original)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )),\n",
       " ('model.transformer.h.5.ln_1', LayerNorm()),\n",
       " ('model.transformer.h.5.attn',\n",
       "  CausalSelfAttention(\n",
       "    (c_attn): SplitLinear(\n",
       "      (splits): ModuleList(\n",
       "        (0-35): 36 x ShareLinear(in=768, basis=768, out=64, state=original)\n",
       "      )\n",
       "    )\n",
       "    (c_proj): SplitLinear(\n",
       "      (splits): ModuleList(\n",
       "        (0): ShareLinear(in=768, basis=768, out=768, state=original)\n",
       "      )\n",
       "    )\n",
       "    (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "  )),\n",
       " ('model.transformer.h.5.attn.c_attn',\n",
       "  SplitLinear(\n",
       "    (splits): ModuleList(\n",
       "      (0-35): 36 x ShareLinear(in=768, basis=768, out=64, state=original)\n",
       "    )\n",
       "  )),\n",
       " ('model.transformer.h.5.attn.c_attn.splits',\n",
       "  ModuleList(\n",
       "    (0-35): 36 x ShareLinear(in=768, basis=768, out=64, state=original)\n",
       "  )),\n",
       " ('model.transformer.h.5.attn.c_attn.splits.0',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.5.attn.c_attn.splits.1',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.5.attn.c_attn.splits.2',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.5.attn.c_attn.splits.3',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.5.attn.c_attn.splits.4',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.5.attn.c_attn.splits.5',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.5.attn.c_attn.splits.6',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.5.attn.c_attn.splits.7',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.5.attn.c_attn.splits.8',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.5.attn.c_attn.splits.9',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.5.attn.c_attn.splits.10',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.5.attn.c_attn.splits.11',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.5.attn.c_attn.splits.12',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.5.attn.c_attn.splits.13',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.5.attn.c_attn.splits.14',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.5.attn.c_attn.splits.15',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.5.attn.c_attn.splits.16',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.5.attn.c_attn.splits.17',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.5.attn.c_attn.splits.18',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.5.attn.c_attn.splits.19',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.5.attn.c_attn.splits.20',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.5.attn.c_attn.splits.21',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.5.attn.c_attn.splits.22',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.5.attn.c_attn.splits.23',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.5.attn.c_attn.splits.24',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.5.attn.c_attn.splits.25',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.5.attn.c_attn.splits.26',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.5.attn.c_attn.splits.27',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.5.attn.c_attn.splits.28',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.5.attn.c_attn.splits.29',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.5.attn.c_attn.splits.30',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.5.attn.c_attn.splits.31',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.5.attn.c_attn.splits.32',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.5.attn.c_attn.splits.33',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.5.attn.c_attn.splits.34',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.5.attn.c_attn.splits.35',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.5.attn.c_proj',\n",
       "  SplitLinear(\n",
       "    (splits): ModuleList(\n",
       "      (0): ShareLinear(in=768, basis=768, out=768, state=original)\n",
       "    )\n",
       "  )),\n",
       " ('model.transformer.h.5.attn.c_proj.splits',\n",
       "  ModuleList(\n",
       "    (0): ShareLinear(in=768, basis=768, out=768, state=original)\n",
       "  )),\n",
       " ('model.transformer.h.5.attn.c_proj.splits.0',\n",
       "  ShareLinear(in=768, basis=768, out=768, state=original)),\n",
       " ('model.transformer.h.5.attn.attn_dropout', Dropout(p=0.0, inplace=False)),\n",
       " ('model.transformer.h.5.attn.resid_dropout', Dropout(p=0.0, inplace=False)),\n",
       " ('model.transformer.h.5.ln_2', LayerNorm()),\n",
       " ('model.transformer.h.5.mlp',\n",
       "  MLP(\n",
       "    (c_fc): SplitLinear(\n",
       "      (splits): ModuleList(\n",
       "        (0): ShareLinear(in=768, basis=768, out=3072, state=original)\n",
       "      )\n",
       "    )\n",
       "    (gelu): GELU(approximate='none')\n",
       "    (c_proj): SplitLinear(\n",
       "      (splits): ModuleList(\n",
       "        (0): ShareLinear(in=3072, basis=3072, out=768, state=original)\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )),\n",
       " ('model.transformer.h.5.mlp.c_fc',\n",
       "  SplitLinear(\n",
       "    (splits): ModuleList(\n",
       "      (0): ShareLinear(in=768, basis=768, out=3072, state=original)\n",
       "    )\n",
       "  )),\n",
       " ('model.transformer.h.5.mlp.c_fc.splits',\n",
       "  ModuleList(\n",
       "    (0): ShareLinear(in=768, basis=768, out=3072, state=original)\n",
       "  )),\n",
       " ('model.transformer.h.5.mlp.c_fc.splits.0',\n",
       "  ShareLinear(in=768, basis=768, out=3072, state=original)),\n",
       " ('model.transformer.h.5.mlp.gelu', GELU(approximate='none')),\n",
       " ('model.transformer.h.5.mlp.c_proj',\n",
       "  SplitLinear(\n",
       "    (splits): ModuleList(\n",
       "      (0): ShareLinear(in=3072, basis=3072, out=768, state=original)\n",
       "    )\n",
       "  )),\n",
       " ('model.transformer.h.5.mlp.c_proj.splits',\n",
       "  ModuleList(\n",
       "    (0): ShareLinear(in=3072, basis=3072, out=768, state=original)\n",
       "  )),\n",
       " ('model.transformer.h.5.mlp.c_proj.splits.0',\n",
       "  ShareLinear(in=3072, basis=3072, out=768, state=original)),\n",
       " ('model.transformer.h.5.mlp.dropout', Dropout(p=0.0, inplace=False)),\n",
       " ('model.transformer.h.6',\n",
       "  Block(\n",
       "    (ln_1): LayerNorm()\n",
       "    (attn): CausalSelfAttention(\n",
       "      (c_attn): SplitLinear(\n",
       "        (splits): ModuleList(\n",
       "          (0-35): 36 x ShareLinear(in=768, basis=768, out=64, state=original)\n",
       "        )\n",
       "      )\n",
       "      (c_proj): SplitLinear(\n",
       "        (splits): ModuleList(\n",
       "          (0): ShareLinear(in=768, basis=768, out=768, state=original)\n",
       "        )\n",
       "      )\n",
       "      (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "      (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (ln_2): LayerNorm()\n",
       "    (mlp): MLP(\n",
       "      (c_fc): SplitLinear(\n",
       "        (splits): ModuleList(\n",
       "          (0): ShareLinear(in=768, basis=768, out=3072, state=original)\n",
       "        )\n",
       "      )\n",
       "      (gelu): GELU(approximate='none')\n",
       "      (c_proj): SplitLinear(\n",
       "        (splits): ModuleList(\n",
       "          (0): ShareLinear(in=3072, basis=3072, out=768, state=original)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )),\n",
       " ('model.transformer.h.6.ln_1', LayerNorm()),\n",
       " ('model.transformer.h.6.attn',\n",
       "  CausalSelfAttention(\n",
       "    (c_attn): SplitLinear(\n",
       "      (splits): ModuleList(\n",
       "        (0-35): 36 x ShareLinear(in=768, basis=768, out=64, state=original)\n",
       "      )\n",
       "    )\n",
       "    (c_proj): SplitLinear(\n",
       "      (splits): ModuleList(\n",
       "        (0): ShareLinear(in=768, basis=768, out=768, state=original)\n",
       "      )\n",
       "    )\n",
       "    (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "  )),\n",
       " ('model.transformer.h.6.attn.c_attn',\n",
       "  SplitLinear(\n",
       "    (splits): ModuleList(\n",
       "      (0-35): 36 x ShareLinear(in=768, basis=768, out=64, state=original)\n",
       "    )\n",
       "  )),\n",
       " ('model.transformer.h.6.attn.c_attn.splits',\n",
       "  ModuleList(\n",
       "    (0-35): 36 x ShareLinear(in=768, basis=768, out=64, state=original)\n",
       "  )),\n",
       " ('model.transformer.h.6.attn.c_attn.splits.0',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.6.attn.c_attn.splits.1',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.6.attn.c_attn.splits.2',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.6.attn.c_attn.splits.3',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.6.attn.c_attn.splits.4',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.6.attn.c_attn.splits.5',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.6.attn.c_attn.splits.6',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.6.attn.c_attn.splits.7',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.6.attn.c_attn.splits.8',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.6.attn.c_attn.splits.9',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.6.attn.c_attn.splits.10',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.6.attn.c_attn.splits.11',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.6.attn.c_attn.splits.12',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.6.attn.c_attn.splits.13',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.6.attn.c_attn.splits.14',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.6.attn.c_attn.splits.15',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.6.attn.c_attn.splits.16',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.6.attn.c_attn.splits.17',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.6.attn.c_attn.splits.18',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.6.attn.c_attn.splits.19',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.6.attn.c_attn.splits.20',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.6.attn.c_attn.splits.21',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.6.attn.c_attn.splits.22',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.6.attn.c_attn.splits.23',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.6.attn.c_attn.splits.24',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.6.attn.c_attn.splits.25',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.6.attn.c_attn.splits.26',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.6.attn.c_attn.splits.27',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.6.attn.c_attn.splits.28',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.6.attn.c_attn.splits.29',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.6.attn.c_attn.splits.30',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.6.attn.c_attn.splits.31',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.6.attn.c_attn.splits.32',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.6.attn.c_attn.splits.33',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.6.attn.c_attn.splits.34',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.6.attn.c_attn.splits.35',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.6.attn.c_proj',\n",
       "  SplitLinear(\n",
       "    (splits): ModuleList(\n",
       "      (0): ShareLinear(in=768, basis=768, out=768, state=original)\n",
       "    )\n",
       "  )),\n",
       " ('model.transformer.h.6.attn.c_proj.splits',\n",
       "  ModuleList(\n",
       "    (0): ShareLinear(in=768, basis=768, out=768, state=original)\n",
       "  )),\n",
       " ('model.transformer.h.6.attn.c_proj.splits.0',\n",
       "  ShareLinear(in=768, basis=768, out=768, state=original)),\n",
       " ('model.transformer.h.6.attn.attn_dropout', Dropout(p=0.0, inplace=False)),\n",
       " ('model.transformer.h.6.attn.resid_dropout', Dropout(p=0.0, inplace=False)),\n",
       " ('model.transformer.h.6.ln_2', LayerNorm()),\n",
       " ('model.transformer.h.6.mlp',\n",
       "  MLP(\n",
       "    (c_fc): SplitLinear(\n",
       "      (splits): ModuleList(\n",
       "        (0): ShareLinear(in=768, basis=768, out=3072, state=original)\n",
       "      )\n",
       "    )\n",
       "    (gelu): GELU(approximate='none')\n",
       "    (c_proj): SplitLinear(\n",
       "      (splits): ModuleList(\n",
       "        (0): ShareLinear(in=3072, basis=3072, out=768, state=original)\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )),\n",
       " ('model.transformer.h.6.mlp.c_fc',\n",
       "  SplitLinear(\n",
       "    (splits): ModuleList(\n",
       "      (0): ShareLinear(in=768, basis=768, out=3072, state=original)\n",
       "    )\n",
       "  )),\n",
       " ('model.transformer.h.6.mlp.c_fc.splits',\n",
       "  ModuleList(\n",
       "    (0): ShareLinear(in=768, basis=768, out=3072, state=original)\n",
       "  )),\n",
       " ('model.transformer.h.6.mlp.c_fc.splits.0',\n",
       "  ShareLinear(in=768, basis=768, out=3072, state=original)),\n",
       " ('model.transformer.h.6.mlp.gelu', GELU(approximate='none')),\n",
       " ('model.transformer.h.6.mlp.c_proj',\n",
       "  SplitLinear(\n",
       "    (splits): ModuleList(\n",
       "      (0): ShareLinear(in=3072, basis=3072, out=768, state=original)\n",
       "    )\n",
       "  )),\n",
       " ('model.transformer.h.6.mlp.c_proj.splits',\n",
       "  ModuleList(\n",
       "    (0): ShareLinear(in=3072, basis=3072, out=768, state=original)\n",
       "  )),\n",
       " ('model.transformer.h.6.mlp.c_proj.splits.0',\n",
       "  ShareLinear(in=3072, basis=3072, out=768, state=original)),\n",
       " ('model.transformer.h.6.mlp.dropout', Dropout(p=0.0, inplace=False)),\n",
       " ('model.transformer.h.7',\n",
       "  Block(\n",
       "    (ln_1): LayerNorm()\n",
       "    (attn): CausalSelfAttention(\n",
       "      (c_attn): SplitLinear(\n",
       "        (splits): ModuleList(\n",
       "          (0-35): 36 x ShareLinear(in=768, basis=768, out=64, state=original)\n",
       "        )\n",
       "      )\n",
       "      (c_proj): SplitLinear(\n",
       "        (splits): ModuleList(\n",
       "          (0): ShareLinear(in=768, basis=768, out=768, state=original)\n",
       "        )\n",
       "      )\n",
       "      (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "      (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (ln_2): LayerNorm()\n",
       "    (mlp): MLP(\n",
       "      (c_fc): SplitLinear(\n",
       "        (splits): ModuleList(\n",
       "          (0): ShareLinear(in=768, basis=768, out=3072, state=original)\n",
       "        )\n",
       "      )\n",
       "      (gelu): GELU(approximate='none')\n",
       "      (c_proj): SplitLinear(\n",
       "        (splits): ModuleList(\n",
       "          (0): ShareLinear(in=3072, basis=3072, out=768, state=original)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )),\n",
       " ('model.transformer.h.7.ln_1', LayerNorm()),\n",
       " ('model.transformer.h.7.attn',\n",
       "  CausalSelfAttention(\n",
       "    (c_attn): SplitLinear(\n",
       "      (splits): ModuleList(\n",
       "        (0-35): 36 x ShareLinear(in=768, basis=768, out=64, state=original)\n",
       "      )\n",
       "    )\n",
       "    (c_proj): SplitLinear(\n",
       "      (splits): ModuleList(\n",
       "        (0): ShareLinear(in=768, basis=768, out=768, state=original)\n",
       "      )\n",
       "    )\n",
       "    (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "  )),\n",
       " ('model.transformer.h.7.attn.c_attn',\n",
       "  SplitLinear(\n",
       "    (splits): ModuleList(\n",
       "      (0-35): 36 x ShareLinear(in=768, basis=768, out=64, state=original)\n",
       "    )\n",
       "  )),\n",
       " ('model.transformer.h.7.attn.c_attn.splits',\n",
       "  ModuleList(\n",
       "    (0-35): 36 x ShareLinear(in=768, basis=768, out=64, state=original)\n",
       "  )),\n",
       " ('model.transformer.h.7.attn.c_attn.splits.0',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.7.attn.c_attn.splits.1',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.7.attn.c_attn.splits.2',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.7.attn.c_attn.splits.3',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.7.attn.c_attn.splits.4',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.7.attn.c_attn.splits.5',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.7.attn.c_attn.splits.6',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.7.attn.c_attn.splits.7',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.7.attn.c_attn.splits.8',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.7.attn.c_attn.splits.9',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.7.attn.c_attn.splits.10',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.7.attn.c_attn.splits.11',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.7.attn.c_attn.splits.12',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.7.attn.c_attn.splits.13',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.7.attn.c_attn.splits.14',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.7.attn.c_attn.splits.15',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.7.attn.c_attn.splits.16',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.7.attn.c_attn.splits.17',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.7.attn.c_attn.splits.18',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.7.attn.c_attn.splits.19',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.7.attn.c_attn.splits.20',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.7.attn.c_attn.splits.21',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.7.attn.c_attn.splits.22',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.7.attn.c_attn.splits.23',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.7.attn.c_attn.splits.24',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.7.attn.c_attn.splits.25',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.7.attn.c_attn.splits.26',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.7.attn.c_attn.splits.27',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.7.attn.c_attn.splits.28',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.7.attn.c_attn.splits.29',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.7.attn.c_attn.splits.30',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.7.attn.c_attn.splits.31',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.7.attn.c_attn.splits.32',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.7.attn.c_attn.splits.33',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.7.attn.c_attn.splits.34',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.7.attn.c_attn.splits.35',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.7.attn.c_proj',\n",
       "  SplitLinear(\n",
       "    (splits): ModuleList(\n",
       "      (0): ShareLinear(in=768, basis=768, out=768, state=original)\n",
       "    )\n",
       "  )),\n",
       " ('model.transformer.h.7.attn.c_proj.splits',\n",
       "  ModuleList(\n",
       "    (0): ShareLinear(in=768, basis=768, out=768, state=original)\n",
       "  )),\n",
       " ('model.transformer.h.7.attn.c_proj.splits.0',\n",
       "  ShareLinear(in=768, basis=768, out=768, state=original)),\n",
       " ('model.transformer.h.7.attn.attn_dropout', Dropout(p=0.0, inplace=False)),\n",
       " ('model.transformer.h.7.attn.resid_dropout', Dropout(p=0.0, inplace=False)),\n",
       " ('model.transformer.h.7.ln_2', LayerNorm()),\n",
       " ('model.transformer.h.7.mlp',\n",
       "  MLP(\n",
       "    (c_fc): SplitLinear(\n",
       "      (splits): ModuleList(\n",
       "        (0): ShareLinear(in=768, basis=768, out=3072, state=original)\n",
       "      )\n",
       "    )\n",
       "    (gelu): GELU(approximate='none')\n",
       "    (c_proj): SplitLinear(\n",
       "      (splits): ModuleList(\n",
       "        (0): ShareLinear(in=3072, basis=3072, out=768, state=original)\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )),\n",
       " ('model.transformer.h.7.mlp.c_fc',\n",
       "  SplitLinear(\n",
       "    (splits): ModuleList(\n",
       "      (0): ShareLinear(in=768, basis=768, out=3072, state=original)\n",
       "    )\n",
       "  )),\n",
       " ('model.transformer.h.7.mlp.c_fc.splits',\n",
       "  ModuleList(\n",
       "    (0): ShareLinear(in=768, basis=768, out=3072, state=original)\n",
       "  )),\n",
       " ('model.transformer.h.7.mlp.c_fc.splits.0',\n",
       "  ShareLinear(in=768, basis=768, out=3072, state=original)),\n",
       " ('model.transformer.h.7.mlp.gelu', GELU(approximate='none')),\n",
       " ('model.transformer.h.7.mlp.c_proj',\n",
       "  SplitLinear(\n",
       "    (splits): ModuleList(\n",
       "      (0): ShareLinear(in=3072, basis=3072, out=768, state=original)\n",
       "    )\n",
       "  )),\n",
       " ('model.transformer.h.7.mlp.c_proj.splits',\n",
       "  ModuleList(\n",
       "    (0): ShareLinear(in=3072, basis=3072, out=768, state=original)\n",
       "  )),\n",
       " ('model.transformer.h.7.mlp.c_proj.splits.0',\n",
       "  ShareLinear(in=3072, basis=3072, out=768, state=original)),\n",
       " ('model.transformer.h.7.mlp.dropout', Dropout(p=0.0, inplace=False)),\n",
       " ('model.transformer.h.8',\n",
       "  Block(\n",
       "    (ln_1): LayerNorm()\n",
       "    (attn): CausalSelfAttention(\n",
       "      (c_attn): SplitLinear(\n",
       "        (splits): ModuleList(\n",
       "          (0-35): 36 x ShareLinear(in=768, basis=768, out=64, state=original)\n",
       "        )\n",
       "      )\n",
       "      (c_proj): SplitLinear(\n",
       "        (splits): ModuleList(\n",
       "          (0): ShareLinear(in=768, basis=768, out=768, state=original)\n",
       "        )\n",
       "      )\n",
       "      (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "      (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (ln_2): LayerNorm()\n",
       "    (mlp): MLP(\n",
       "      (c_fc): SplitLinear(\n",
       "        (splits): ModuleList(\n",
       "          (0): ShareLinear(in=768, basis=768, out=3072, state=original)\n",
       "        )\n",
       "      )\n",
       "      (gelu): GELU(approximate='none')\n",
       "      (c_proj): SplitLinear(\n",
       "        (splits): ModuleList(\n",
       "          (0): ShareLinear(in=3072, basis=3072, out=768, state=original)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )),\n",
       " ('model.transformer.h.8.ln_1', LayerNorm()),\n",
       " ('model.transformer.h.8.attn',\n",
       "  CausalSelfAttention(\n",
       "    (c_attn): SplitLinear(\n",
       "      (splits): ModuleList(\n",
       "        (0-35): 36 x ShareLinear(in=768, basis=768, out=64, state=original)\n",
       "      )\n",
       "    )\n",
       "    (c_proj): SplitLinear(\n",
       "      (splits): ModuleList(\n",
       "        (0): ShareLinear(in=768, basis=768, out=768, state=original)\n",
       "      )\n",
       "    )\n",
       "    (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "  )),\n",
       " ('model.transformer.h.8.attn.c_attn',\n",
       "  SplitLinear(\n",
       "    (splits): ModuleList(\n",
       "      (0-35): 36 x ShareLinear(in=768, basis=768, out=64, state=original)\n",
       "    )\n",
       "  )),\n",
       " ('model.transformer.h.8.attn.c_attn.splits',\n",
       "  ModuleList(\n",
       "    (0-35): 36 x ShareLinear(in=768, basis=768, out=64, state=original)\n",
       "  )),\n",
       " ('model.transformer.h.8.attn.c_attn.splits.0',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.8.attn.c_attn.splits.1',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.8.attn.c_attn.splits.2',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.8.attn.c_attn.splits.3',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.8.attn.c_attn.splits.4',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.8.attn.c_attn.splits.5',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.8.attn.c_attn.splits.6',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.8.attn.c_attn.splits.7',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.8.attn.c_attn.splits.8',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.8.attn.c_attn.splits.9',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.8.attn.c_attn.splits.10',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.8.attn.c_attn.splits.11',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.8.attn.c_attn.splits.12',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.8.attn.c_attn.splits.13',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.8.attn.c_attn.splits.14',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.8.attn.c_attn.splits.15',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.8.attn.c_attn.splits.16',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.8.attn.c_attn.splits.17',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.8.attn.c_attn.splits.18',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.8.attn.c_attn.splits.19',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.8.attn.c_attn.splits.20',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.8.attn.c_attn.splits.21',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.8.attn.c_attn.splits.22',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.8.attn.c_attn.splits.23',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.8.attn.c_attn.splits.24',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.8.attn.c_attn.splits.25',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.8.attn.c_attn.splits.26',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.8.attn.c_attn.splits.27',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.8.attn.c_attn.splits.28',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.8.attn.c_attn.splits.29',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.8.attn.c_attn.splits.30',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.8.attn.c_attn.splits.31',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.8.attn.c_attn.splits.32',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.8.attn.c_attn.splits.33',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.8.attn.c_attn.splits.34',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.8.attn.c_attn.splits.35',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.8.attn.c_proj',\n",
       "  SplitLinear(\n",
       "    (splits): ModuleList(\n",
       "      (0): ShareLinear(in=768, basis=768, out=768, state=original)\n",
       "    )\n",
       "  )),\n",
       " ('model.transformer.h.8.attn.c_proj.splits',\n",
       "  ModuleList(\n",
       "    (0): ShareLinear(in=768, basis=768, out=768, state=original)\n",
       "  )),\n",
       " ('model.transformer.h.8.attn.c_proj.splits.0',\n",
       "  ShareLinear(in=768, basis=768, out=768, state=original)),\n",
       " ('model.transformer.h.8.attn.attn_dropout', Dropout(p=0.0, inplace=False)),\n",
       " ('model.transformer.h.8.attn.resid_dropout', Dropout(p=0.0, inplace=False)),\n",
       " ('model.transformer.h.8.ln_2', LayerNorm()),\n",
       " ('model.transformer.h.8.mlp',\n",
       "  MLP(\n",
       "    (c_fc): SplitLinear(\n",
       "      (splits): ModuleList(\n",
       "        (0): ShareLinear(in=768, basis=768, out=3072, state=original)\n",
       "      )\n",
       "    )\n",
       "    (gelu): GELU(approximate='none')\n",
       "    (c_proj): SplitLinear(\n",
       "      (splits): ModuleList(\n",
       "        (0): ShareLinear(in=3072, basis=3072, out=768, state=original)\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )),\n",
       " ('model.transformer.h.8.mlp.c_fc',\n",
       "  SplitLinear(\n",
       "    (splits): ModuleList(\n",
       "      (0): ShareLinear(in=768, basis=768, out=3072, state=original)\n",
       "    )\n",
       "  )),\n",
       " ('model.transformer.h.8.mlp.c_fc.splits',\n",
       "  ModuleList(\n",
       "    (0): ShareLinear(in=768, basis=768, out=3072, state=original)\n",
       "  )),\n",
       " ('model.transformer.h.8.mlp.c_fc.splits.0',\n",
       "  ShareLinear(in=768, basis=768, out=3072, state=original)),\n",
       " ('model.transformer.h.8.mlp.gelu', GELU(approximate='none')),\n",
       " ('model.transformer.h.8.mlp.c_proj',\n",
       "  SplitLinear(\n",
       "    (splits): ModuleList(\n",
       "      (0): ShareLinear(in=3072, basis=3072, out=768, state=original)\n",
       "    )\n",
       "  )),\n",
       " ('model.transformer.h.8.mlp.c_proj.splits',\n",
       "  ModuleList(\n",
       "    (0): ShareLinear(in=3072, basis=3072, out=768, state=original)\n",
       "  )),\n",
       " ('model.transformer.h.8.mlp.c_proj.splits.0',\n",
       "  ShareLinear(in=3072, basis=3072, out=768, state=original)),\n",
       " ('model.transformer.h.8.mlp.dropout', Dropout(p=0.0, inplace=False)),\n",
       " ('model.transformer.h.9',\n",
       "  Block(\n",
       "    (ln_1): LayerNorm()\n",
       "    (attn): CausalSelfAttention(\n",
       "      (c_attn): SplitLinear(\n",
       "        (splits): ModuleList(\n",
       "          (0-35): 36 x ShareLinear(in=768, basis=768, out=64, state=original)\n",
       "        )\n",
       "      )\n",
       "      (c_proj): SplitLinear(\n",
       "        (splits): ModuleList(\n",
       "          (0): ShareLinear(in=768, basis=768, out=768, state=original)\n",
       "        )\n",
       "      )\n",
       "      (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "      (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (ln_2): LayerNorm()\n",
       "    (mlp): MLP(\n",
       "      (c_fc): SplitLinear(\n",
       "        (splits): ModuleList(\n",
       "          (0): ShareLinear(in=768, basis=768, out=3072, state=original)\n",
       "        )\n",
       "      )\n",
       "      (gelu): GELU(approximate='none')\n",
       "      (c_proj): SplitLinear(\n",
       "        (splits): ModuleList(\n",
       "          (0): ShareLinear(in=3072, basis=3072, out=768, state=original)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )),\n",
       " ('model.transformer.h.9.ln_1', LayerNorm()),\n",
       " ('model.transformer.h.9.attn',\n",
       "  CausalSelfAttention(\n",
       "    (c_attn): SplitLinear(\n",
       "      (splits): ModuleList(\n",
       "        (0-35): 36 x ShareLinear(in=768, basis=768, out=64, state=original)\n",
       "      )\n",
       "    )\n",
       "    (c_proj): SplitLinear(\n",
       "      (splits): ModuleList(\n",
       "        (0): ShareLinear(in=768, basis=768, out=768, state=original)\n",
       "      )\n",
       "    )\n",
       "    (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "  )),\n",
       " ('model.transformer.h.9.attn.c_attn',\n",
       "  SplitLinear(\n",
       "    (splits): ModuleList(\n",
       "      (0-35): 36 x ShareLinear(in=768, basis=768, out=64, state=original)\n",
       "    )\n",
       "  )),\n",
       " ('model.transformer.h.9.attn.c_attn.splits',\n",
       "  ModuleList(\n",
       "    (0-35): 36 x ShareLinear(in=768, basis=768, out=64, state=original)\n",
       "  )),\n",
       " ('model.transformer.h.9.attn.c_attn.splits.0',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.9.attn.c_attn.splits.1',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.9.attn.c_attn.splits.2',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.9.attn.c_attn.splits.3',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.9.attn.c_attn.splits.4',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.9.attn.c_attn.splits.5',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.9.attn.c_attn.splits.6',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.9.attn.c_attn.splits.7',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.9.attn.c_attn.splits.8',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.9.attn.c_attn.splits.9',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.9.attn.c_attn.splits.10',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.9.attn.c_attn.splits.11',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.9.attn.c_attn.splits.12',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.9.attn.c_attn.splits.13',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.9.attn.c_attn.splits.14',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.9.attn.c_attn.splits.15',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.9.attn.c_attn.splits.16',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.9.attn.c_attn.splits.17',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.9.attn.c_attn.splits.18',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.9.attn.c_attn.splits.19',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.9.attn.c_attn.splits.20',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.9.attn.c_attn.splits.21',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.9.attn.c_attn.splits.22',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.9.attn.c_attn.splits.23',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.9.attn.c_attn.splits.24',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.9.attn.c_attn.splits.25',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.9.attn.c_attn.splits.26',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.9.attn.c_attn.splits.27',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.9.attn.c_attn.splits.28',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.9.attn.c_attn.splits.29',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.9.attn.c_attn.splits.30',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.9.attn.c_attn.splits.31',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.9.attn.c_attn.splits.32',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.9.attn.c_attn.splits.33',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.9.attn.c_attn.splits.34',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.9.attn.c_attn.splits.35',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.9.attn.c_proj',\n",
       "  SplitLinear(\n",
       "    (splits): ModuleList(\n",
       "      (0): ShareLinear(in=768, basis=768, out=768, state=original)\n",
       "    )\n",
       "  )),\n",
       " ('model.transformer.h.9.attn.c_proj.splits',\n",
       "  ModuleList(\n",
       "    (0): ShareLinear(in=768, basis=768, out=768, state=original)\n",
       "  )),\n",
       " ('model.transformer.h.9.attn.c_proj.splits.0',\n",
       "  ShareLinear(in=768, basis=768, out=768, state=original)),\n",
       " ('model.transformer.h.9.attn.attn_dropout', Dropout(p=0.0, inplace=False)),\n",
       " ('model.transformer.h.9.attn.resid_dropout', Dropout(p=0.0, inplace=False)),\n",
       " ('model.transformer.h.9.ln_2', LayerNorm()),\n",
       " ('model.transformer.h.9.mlp',\n",
       "  MLP(\n",
       "    (c_fc): SplitLinear(\n",
       "      (splits): ModuleList(\n",
       "        (0): ShareLinear(in=768, basis=768, out=3072, state=original)\n",
       "      )\n",
       "    )\n",
       "    (gelu): GELU(approximate='none')\n",
       "    (c_proj): SplitLinear(\n",
       "      (splits): ModuleList(\n",
       "        (0): ShareLinear(in=3072, basis=3072, out=768, state=original)\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )),\n",
       " ('model.transformer.h.9.mlp.c_fc',\n",
       "  SplitLinear(\n",
       "    (splits): ModuleList(\n",
       "      (0): ShareLinear(in=768, basis=768, out=3072, state=original)\n",
       "    )\n",
       "  )),\n",
       " ('model.transformer.h.9.mlp.c_fc.splits',\n",
       "  ModuleList(\n",
       "    (0): ShareLinear(in=768, basis=768, out=3072, state=original)\n",
       "  )),\n",
       " ('model.transformer.h.9.mlp.c_fc.splits.0',\n",
       "  ShareLinear(in=768, basis=768, out=3072, state=original)),\n",
       " ('model.transformer.h.9.mlp.gelu', GELU(approximate='none')),\n",
       " ('model.transformer.h.9.mlp.c_proj',\n",
       "  SplitLinear(\n",
       "    (splits): ModuleList(\n",
       "      (0): ShareLinear(in=3072, basis=3072, out=768, state=original)\n",
       "    )\n",
       "  )),\n",
       " ('model.transformer.h.9.mlp.c_proj.splits',\n",
       "  ModuleList(\n",
       "    (0): ShareLinear(in=3072, basis=3072, out=768, state=original)\n",
       "  )),\n",
       " ('model.transformer.h.9.mlp.c_proj.splits.0',\n",
       "  ShareLinear(in=3072, basis=3072, out=768, state=original)),\n",
       " ('model.transformer.h.9.mlp.dropout', Dropout(p=0.0, inplace=False)),\n",
       " ('model.transformer.h.10',\n",
       "  Block(\n",
       "    (ln_1): LayerNorm()\n",
       "    (attn): CausalSelfAttention(\n",
       "      (c_attn): SplitLinear(\n",
       "        (splits): ModuleList(\n",
       "          (0-35): 36 x ShareLinear(in=768, basis=768, out=64, state=original)\n",
       "        )\n",
       "      )\n",
       "      (c_proj): SplitLinear(\n",
       "        (splits): ModuleList(\n",
       "          (0): ShareLinear(in=768, basis=768, out=768, state=original)\n",
       "        )\n",
       "      )\n",
       "      (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "      (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (ln_2): LayerNorm()\n",
       "    (mlp): MLP(\n",
       "      (c_fc): SplitLinear(\n",
       "        (splits): ModuleList(\n",
       "          (0): ShareLinear(in=768, basis=768, out=3072, state=original)\n",
       "        )\n",
       "      )\n",
       "      (gelu): GELU(approximate='none')\n",
       "      (c_proj): SplitLinear(\n",
       "        (splits): ModuleList(\n",
       "          (0): ShareLinear(in=3072, basis=3072, out=768, state=original)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )),\n",
       " ('model.transformer.h.10.ln_1', LayerNorm()),\n",
       " ('model.transformer.h.10.attn',\n",
       "  CausalSelfAttention(\n",
       "    (c_attn): SplitLinear(\n",
       "      (splits): ModuleList(\n",
       "        (0-35): 36 x ShareLinear(in=768, basis=768, out=64, state=original)\n",
       "      )\n",
       "    )\n",
       "    (c_proj): SplitLinear(\n",
       "      (splits): ModuleList(\n",
       "        (0): ShareLinear(in=768, basis=768, out=768, state=original)\n",
       "      )\n",
       "    )\n",
       "    (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "  )),\n",
       " ('model.transformer.h.10.attn.c_attn',\n",
       "  SplitLinear(\n",
       "    (splits): ModuleList(\n",
       "      (0-35): 36 x ShareLinear(in=768, basis=768, out=64, state=original)\n",
       "    )\n",
       "  )),\n",
       " ('model.transformer.h.10.attn.c_attn.splits',\n",
       "  ModuleList(\n",
       "    (0-35): 36 x ShareLinear(in=768, basis=768, out=64, state=original)\n",
       "  )),\n",
       " ('model.transformer.h.10.attn.c_attn.splits.0',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.10.attn.c_attn.splits.1',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.10.attn.c_attn.splits.2',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.10.attn.c_attn.splits.3',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.10.attn.c_attn.splits.4',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.10.attn.c_attn.splits.5',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.10.attn.c_attn.splits.6',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.10.attn.c_attn.splits.7',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.10.attn.c_attn.splits.8',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.10.attn.c_attn.splits.9',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.10.attn.c_attn.splits.10',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.10.attn.c_attn.splits.11',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.10.attn.c_attn.splits.12',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.10.attn.c_attn.splits.13',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.10.attn.c_attn.splits.14',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.10.attn.c_attn.splits.15',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.10.attn.c_attn.splits.16',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.10.attn.c_attn.splits.17',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.10.attn.c_attn.splits.18',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.10.attn.c_attn.splits.19',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.10.attn.c_attn.splits.20',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.10.attn.c_attn.splits.21',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.10.attn.c_attn.splits.22',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.10.attn.c_attn.splits.23',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.10.attn.c_attn.splits.24',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.10.attn.c_attn.splits.25',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.10.attn.c_attn.splits.26',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.10.attn.c_attn.splits.27',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.10.attn.c_attn.splits.28',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.10.attn.c_attn.splits.29',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.10.attn.c_attn.splits.30',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.10.attn.c_attn.splits.31',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.10.attn.c_attn.splits.32',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.10.attn.c_attn.splits.33',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.10.attn.c_attn.splits.34',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.10.attn.c_attn.splits.35',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.10.attn.c_proj',\n",
       "  SplitLinear(\n",
       "    (splits): ModuleList(\n",
       "      (0): ShareLinear(in=768, basis=768, out=768, state=original)\n",
       "    )\n",
       "  )),\n",
       " ('model.transformer.h.10.attn.c_proj.splits',\n",
       "  ModuleList(\n",
       "    (0): ShareLinear(in=768, basis=768, out=768, state=original)\n",
       "  )),\n",
       " ('model.transformer.h.10.attn.c_proj.splits.0',\n",
       "  ShareLinear(in=768, basis=768, out=768, state=original)),\n",
       " ('model.transformer.h.10.attn.attn_dropout', Dropout(p=0.0, inplace=False)),\n",
       " ('model.transformer.h.10.attn.resid_dropout', Dropout(p=0.0, inplace=False)),\n",
       " ('model.transformer.h.10.ln_2', LayerNorm()),\n",
       " ('model.transformer.h.10.mlp',\n",
       "  MLP(\n",
       "    (c_fc): SplitLinear(\n",
       "      (splits): ModuleList(\n",
       "        (0): ShareLinear(in=768, basis=768, out=3072, state=original)\n",
       "      )\n",
       "    )\n",
       "    (gelu): GELU(approximate='none')\n",
       "    (c_proj): SplitLinear(\n",
       "      (splits): ModuleList(\n",
       "        (0): ShareLinear(in=3072, basis=3072, out=768, state=original)\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )),\n",
       " ('model.transformer.h.10.mlp.c_fc',\n",
       "  SplitLinear(\n",
       "    (splits): ModuleList(\n",
       "      (0): ShareLinear(in=768, basis=768, out=3072, state=original)\n",
       "    )\n",
       "  )),\n",
       " ('model.transformer.h.10.mlp.c_fc.splits',\n",
       "  ModuleList(\n",
       "    (0): ShareLinear(in=768, basis=768, out=3072, state=original)\n",
       "  )),\n",
       " ('model.transformer.h.10.mlp.c_fc.splits.0',\n",
       "  ShareLinear(in=768, basis=768, out=3072, state=original)),\n",
       " ('model.transformer.h.10.mlp.gelu', GELU(approximate='none')),\n",
       " ('model.transformer.h.10.mlp.c_proj',\n",
       "  SplitLinear(\n",
       "    (splits): ModuleList(\n",
       "      (0): ShareLinear(in=3072, basis=3072, out=768, state=original)\n",
       "    )\n",
       "  )),\n",
       " ('model.transformer.h.10.mlp.c_proj.splits',\n",
       "  ModuleList(\n",
       "    (0): ShareLinear(in=3072, basis=3072, out=768, state=original)\n",
       "  )),\n",
       " ('model.transformer.h.10.mlp.c_proj.splits.0',\n",
       "  ShareLinear(in=3072, basis=3072, out=768, state=original)),\n",
       " ('model.transformer.h.10.mlp.dropout', Dropout(p=0.0, inplace=False)),\n",
       " ('model.transformer.h.11',\n",
       "  Block(\n",
       "    (ln_1): LayerNorm()\n",
       "    (attn): CausalSelfAttention(\n",
       "      (c_attn): SplitLinear(\n",
       "        (splits): ModuleList(\n",
       "          (0-35): 36 x ShareLinear(in=768, basis=768, out=64, state=original)\n",
       "        )\n",
       "      )\n",
       "      (c_proj): SplitLinear(\n",
       "        (splits): ModuleList(\n",
       "          (0): ShareLinear(in=768, basis=768, out=768, state=original)\n",
       "        )\n",
       "      )\n",
       "      (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "      (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (ln_2): LayerNorm()\n",
       "    (mlp): MLP(\n",
       "      (c_fc): SplitLinear(\n",
       "        (splits): ModuleList(\n",
       "          (0): ShareLinear(in=768, basis=768, out=3072, state=original)\n",
       "        )\n",
       "      )\n",
       "      (gelu): GELU(approximate='none')\n",
       "      (c_proj): SplitLinear(\n",
       "        (splits): ModuleList(\n",
       "          (0): ShareLinear(in=3072, basis=3072, out=768, state=original)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )),\n",
       " ('model.transformer.h.11.ln_1', LayerNorm()),\n",
       " ('model.transformer.h.11.attn',\n",
       "  CausalSelfAttention(\n",
       "    (c_attn): SplitLinear(\n",
       "      (splits): ModuleList(\n",
       "        (0-35): 36 x ShareLinear(in=768, basis=768, out=64, state=original)\n",
       "      )\n",
       "    )\n",
       "    (c_proj): SplitLinear(\n",
       "      (splits): ModuleList(\n",
       "        (0): ShareLinear(in=768, basis=768, out=768, state=original)\n",
       "      )\n",
       "    )\n",
       "    (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "  )),\n",
       " ('model.transformer.h.11.attn.c_attn',\n",
       "  SplitLinear(\n",
       "    (splits): ModuleList(\n",
       "      (0-35): 36 x ShareLinear(in=768, basis=768, out=64, state=original)\n",
       "    )\n",
       "  )),\n",
       " ('model.transformer.h.11.attn.c_attn.splits',\n",
       "  ModuleList(\n",
       "    (0-35): 36 x ShareLinear(in=768, basis=768, out=64, state=original)\n",
       "  )),\n",
       " ('model.transformer.h.11.attn.c_attn.splits.0',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.11.attn.c_attn.splits.1',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.11.attn.c_attn.splits.2',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.11.attn.c_attn.splits.3',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.11.attn.c_attn.splits.4',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.11.attn.c_attn.splits.5',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.11.attn.c_attn.splits.6',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.11.attn.c_attn.splits.7',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.11.attn.c_attn.splits.8',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.11.attn.c_attn.splits.9',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.11.attn.c_attn.splits.10',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.11.attn.c_attn.splits.11',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.11.attn.c_attn.splits.12',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.11.attn.c_attn.splits.13',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.11.attn.c_attn.splits.14',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.11.attn.c_attn.splits.15',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.11.attn.c_attn.splits.16',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.11.attn.c_attn.splits.17',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.11.attn.c_attn.splits.18',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.11.attn.c_attn.splits.19',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.11.attn.c_attn.splits.20',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.11.attn.c_attn.splits.21',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.11.attn.c_attn.splits.22',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.11.attn.c_attn.splits.23',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.11.attn.c_attn.splits.24',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.11.attn.c_attn.splits.25',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.11.attn.c_attn.splits.26',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.11.attn.c_attn.splits.27',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.11.attn.c_attn.splits.28',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.11.attn.c_attn.splits.29',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.11.attn.c_attn.splits.30',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.11.attn.c_attn.splits.31',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.11.attn.c_attn.splits.32',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.11.attn.c_attn.splits.33',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.11.attn.c_attn.splits.34',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.11.attn.c_attn.splits.35',\n",
       "  ShareLinear(in=768, basis=768, out=64, state=original)),\n",
       " ('model.transformer.h.11.attn.c_proj',\n",
       "  SplitLinear(\n",
       "    (splits): ModuleList(\n",
       "      (0): ShareLinear(in=768, basis=768, out=768, state=original)\n",
       "    )\n",
       "  )),\n",
       " ('model.transformer.h.11.attn.c_proj.splits',\n",
       "  ModuleList(\n",
       "    (0): ShareLinear(in=768, basis=768, out=768, state=original)\n",
       "  )),\n",
       " ('model.transformer.h.11.attn.c_proj.splits.0',\n",
       "  ShareLinear(in=768, basis=768, out=768, state=original)),\n",
       " ('model.transformer.h.11.attn.attn_dropout', Dropout(p=0.0, inplace=False)),\n",
       " ('model.transformer.h.11.attn.resid_dropout', Dropout(p=0.0, inplace=False)),\n",
       " ('model.transformer.h.11.ln_2', LayerNorm()),\n",
       " ('model.transformer.h.11.mlp',\n",
       "  MLP(\n",
       "    (c_fc): SplitLinear(\n",
       "      (splits): ModuleList(\n",
       "        (0): ShareLinear(in=768, basis=768, out=3072, state=original)\n",
       "      )\n",
       "    )\n",
       "    (gelu): GELU(approximate='none')\n",
       "    (c_proj): SplitLinear(\n",
       "      (splits): ModuleList(\n",
       "        (0): ShareLinear(in=3072, basis=3072, out=768, state=original)\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )),\n",
       " ('model.transformer.h.11.mlp.c_fc',\n",
       "  SplitLinear(\n",
       "    (splits): ModuleList(\n",
       "      (0): ShareLinear(in=768, basis=768, out=3072, state=original)\n",
       "    )\n",
       "  )),\n",
       " ('model.transformer.h.11.mlp.c_fc.splits',\n",
       "  ModuleList(\n",
       "    (0): ShareLinear(in=768, basis=768, out=3072, state=original)\n",
       "  )),\n",
       " ('model.transformer.h.11.mlp.c_fc.splits.0',\n",
       "  ShareLinear(in=768, basis=768, out=3072, state=original)),\n",
       " ('model.transformer.h.11.mlp.gelu', GELU(approximate='none')),\n",
       " ('model.transformer.h.11.mlp.c_proj',\n",
       "  SplitLinear(\n",
       "    (splits): ModuleList(\n",
       "      (0): ShareLinear(in=3072, basis=3072, out=768, state=original)\n",
       "    )\n",
       "  )),\n",
       " ('model.transformer.h.11.mlp.c_proj.splits',\n",
       "  ModuleList(\n",
       "    (0): ShareLinear(in=3072, basis=3072, out=768, state=original)\n",
       "  )),\n",
       " ('model.transformer.h.11.mlp.c_proj.splits.0',\n",
       "  ShareLinear(in=3072, basis=3072, out=768, state=original)),\n",
       " ('model.transformer.h.11.mlp.dropout', Dropout(p=0.0, inplace=False)),\n",
       " ('model.transformer.ln_f', LayerNorm()),\n",
       " ('model.lm_head', Linear(in_features=768, out_features=50257, bias=False))]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(foundation.named_modules())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a663bbb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
